{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T17:59:34.957908Z",
     "start_time": "2018-04-19T17:59:33.589261Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import tifffile as tif\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from multiprocessing import Pool\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Merge\n",
    "from collections import Counter\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import one_hot\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T16:55:51.645130Z",
     "start_time": "2018-04-19T16:55:51.622427Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, x_metadata, y_metadata, batch_size, crop_size):\n",
    "        self.x = x_metadata\n",
    "        self.y = y_metadata\n",
    "        self.batch_size = batch_size\n",
    "        self.cp = crop_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        return [np.array([np.transpose(np.array(tif.imread(file_name), dtype=int)/255.0,\n",
    "                                     (1,2,0))[self.cp:-self.cp,self.cp:-self.cp,:]\n",
    "                        for file_name in batch_x]), np.array([np.transpose(np.array(tif.imread(file_name), dtype=int)/255.0,\n",
    "                                     (1,2,0))[self.cp:-self.cp,self.cp:-self.cp,:]\n",
    "                        for file_name in batch_x])], np.array(batch_y)         \n",
    "\n",
    "class CNN_Model:\n",
    "    \n",
    "    def __init__(self, directory):\n",
    "        \n",
    "        self.path = directory\n",
    "        self.classes = sorted(list(os.listdir(self.path+\"/train\")))\n",
    "        \n",
    "        self.train_metadata_x = []\n",
    "        self.train_metadata_y = []\n",
    "        self.test_metadata_x = []\n",
    "        self.test_metadata_y = []\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            for im in os.listdir(self.path+\"/train/\"+cls):\n",
    "                self.train_metadata_x.append(self.path+\"/train/\"+cls+\"/\"+im)\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            for im in os.listdir(self.path+\"/test/\"+cls):\n",
    "                self.test_metadata_x.append(self.path+\"/test/\"+cls+\"/\"+im)\n",
    "        \n",
    "        np.random.shuffle(self.train_metadata_x)\n",
    "        np.random.shuffle(self.test_metadata_x)\n",
    "        \n",
    "        for p in self.train_metadata_x:\n",
    "            y = np.zeros(10, dtype=int)\n",
    "            y[self.classes.index(p.split(\"/\")[3])] = 1\n",
    "            self.train_metadata_y.append(y)\n",
    "            \n",
    "        for p in self.test_metadata_x:\n",
    "            y = np.zeros(10, dtype=int)\n",
    "            y[self.classes.index(p.split(\"/\")[3])] = 1\n",
    "            self.test_metadata_y.append(y)\n",
    "    \n",
    "    def model_create(self):\n",
    "        '''\n",
    "        # Branch 1\n",
    "        branch1 = Sequential()\n",
    "        # Step 1 - Convolution\n",
    "        branch1.add(Conv2D(filters=32, kernel_size=(2, 2), input_shape = (32,32,33), activation = 'relu'))\n",
    "        branch1.add(Conv2D(filters=96, kernel_size=(3, 3), activation = 'relu'))\n",
    "        branch1.add(Conv2D(filters=256, kernel_size=(4, 4), activation = 'relu'))\n",
    "        branch1.add(Conv2D(filters=576, kernel_size=(5, 5), activation = 'relu'))\n",
    "        branch1.add(MaxPool2D(pool_size = (2, 2)))\n",
    "        branch1.summary()\n",
    "        \n",
    "        # Branch 2\n",
    "        branch2 = Sequential()\n",
    "        # Step 1 - Convolution\n",
    "        branch2.add(Conv2D(filters=96, kernel_size=(3, 3), input_shape = (32,32,33), activation = 'relu'))\n",
    "        branch2.add(Conv2D(filters=288, kernel_size=(4, 4), activation = 'relu'))\n",
    "        branch2.add(Conv2D(filters=576, kernel_size=(5, 5), activation = 'relu'))\n",
    "        #branch2.add(Conv2D(filters=, kernel_size=(5, 5), activation = 'relu'))\n",
    "        branch2.add(MaxPool2D(pool_size = (2, 2)))\n",
    "        branch2.summary()\n",
    "        \n",
    "        # Step 3 - Flattening\n",
    "        classifier = Sequential()\n",
    "        classifier.add(Merge([branch1, branch2], mode='concat'))\n",
    "        classifier.add(Flatten())\n",
    "        # Step 4 - Full connection\n",
    "        classifier.add(Dense(128, activation = 'relu'))\n",
    "        classifier.add(Dense(128, activation = 'tanh'))\n",
    "        classifier.add(Dense(10, activation = 'sigmoid'))\n",
    "        # Compiling the CNN\n",
    "        classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "        classifier.summary()\n",
    "        return classifier\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit_generator(self, num_epochs=10, batch_size=32, crop_size=16):        \n",
    "        \n",
    "        classifier = self.model_create()\n",
    "        train_data = ImageDataGenerator(self.train_metadata_x, self.train_metadata_y, batch_size, crop_size)\n",
    "        test_data = ImageDataGenerator(self.test_metadata_x, self.test_metadata_y, batch_size, crop_size)\n",
    "        history = classifier.fit_generator(train_data, epochs=num_epochs, use_multiprocessing=True,shuffle=True)\n",
    "        classifier.evaluate_generator(test_data, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T17:59:42.022000Z",
     "start_time": "2018-04-19T17:59:39.310301Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (36,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"occurrences_train.csv\")\n",
    "#df = df[[\"class\",\"order\"]]\n",
    "#encoded_class = [ one_hot(d,10) for d in list(df['class']) ]\n",
    "#encoded_order = one_hot(df,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T17:59:42.420797Z",
     "start_time": "2018-04-19T17:59:42.416947Z"
    }
   },
   "outputs": [],
   "source": [
    "def encoder(d):\n",
    "    \"\"\"\n",
    "    Pass the input as a pandas series.\n",
    "    \"\"\"\n",
    "    dic = {}\n",
    "    names = sorted(list(d.unique()))\n",
    "    for i in names:\n",
    "        dic[i] = names.index(i)\n",
    "    #d.replace(dic,inplace=True)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T16:27:26.040689Z",
     "start_time": "2018-04-19T16:27:26.020298Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e_class = encoder(df['class'])\n",
    "e_order = encoder(df['order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T16:56:58.210332Z",
     "start_time": "2018-04-19T16:56:58.192849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(encoder(df['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T18:00:18.994447Z",
     "start_time": "2018-04-19T18:00:18.941491Z"
    }
   },
   "outputs": [],
   "source": [
    "pkl.dump(encoder(df['class']),open(\"Data/class_encoding.pkl\",\"wb\"))\n",
    "pkl.dump(encoder(df['order']),open(\"Data/order_encoding.pkl\",\"wb\"))\n",
    "pkl.dump(encoder(df['family']),open(\"Data/family_encoding.pkl\",\"wb\"))\n",
    "pkl.dump(encoder(df['genus']),open(\"Data/genus_encoding.pkl\",\"wb\"))\n",
    "pkl.dump(df['species_glc_id'].unique(),open(\"Data/specie_encoding.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T18:06:28.691676Z",
     "start_time": "2018-04-18T18:06:27.766196Z"
    }
   },
   "outputs": [],
   "source": [
    "ob = CNN_Model(directory=\"Data/Class wise Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T18:07:31.927029Z",
     "start_time": "2018-04-18T18:06:28.694225Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ob.fit_generator(num_epochs=15, batch_size=100, crop_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T17:02:14.786088Z",
     "start_time": "2018-04-19T17:02:14.775158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (2, 4), (5, 10)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "d= {1:1, 2:4, 5:10}\n",
    "\n",
    "sorted(d.items(), key=operator.itemgetter(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T07:58:33.141008Z",
     "start_time": "2018-05-03T07:58:29.319751Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import pandas as pd\n",
    "import tifffile as tif\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T07:58:33.531332Z",
     "start_time": "2018-05-03T07:58:33.525884Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    shape=[]\n",
    "    dic = dict((c, i) for i, c in enumerate(os.listdir(folder)))\n",
    "    for filename in os.listdir(folder):\n",
    "        for image in os.listdir(folder+str(filename)):\n",
    "            #img = Image.open(os.path.join(folder+str(filename)+'/'+str(image))).convert('LA')\n",
    "            img = cv2.imread(os.path.join(folder+str(filename),image))\n",
    "            if img is not None:\n",
    "                images.append(img.transpose((2, 0, 1)) )\n",
    "                shape.append(dic[str(filename)])\n",
    "                break\n",
    "    return images,shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T07:58:34.036542Z",
     "start_time": "2018-05-03T07:58:34.019981Z"
    }
   },
   "outputs": [],
   "source": [
    "class Data_Preprocess():\n",
    "    \n",
    "    def init_load(self, root_dir, csv_file):\n",
    "        self.df = pd.read_csv(csv_file, low_memory=False)\n",
    "        self.path = root_dir\n",
    "        \n",
    "    def create_mappings_for_unique_labels(self):\n",
    "        # getting all unique names from csv file\n",
    "        self.classes = list(sorted(self.df['class'].unique()))\n",
    "        self.orders = list(sorted(self.df['order'].unique()))\n",
    "        self.family = list(sorted(self.df['family'].unique()))\n",
    "        self.genus = list(sorted(self.df['genus'].unique()))\n",
    "        self.species = list(sorted(self.df['species_glc_id'].unique()))\n",
    "        \n",
    "        # creting map for one hot encoding / embedding\n",
    "        self.class_encoding = {}\n",
    "        self.order_encoding = {}\n",
    "        self.family_encoding = {}\n",
    "        self.genus_encoding = {}\n",
    "        self.species_encoding = {}\n",
    "        for i, name in enumerate(self.classes):\n",
    "            self.class_encoding[name] = i\n",
    "        for i, name in enumerate(self.orders):\n",
    "            self.order_encoding[name] = i\n",
    "        for i, name in enumerate(self.family):\n",
    "            self.family_encoding[name] = i\n",
    "        for i, name in enumerate(self.genus):\n",
    "            self.genus_encoding[name] = i\n",
    "        \n",
    "    # embedding all the names\n",
    "    def create_embedding(self):\n",
    "        self.master_dictionary = {}\n",
    "        all_names = self.classes + self.orders + self.family + self.genus + self.species\n",
    "        embed_dim = int(np.ceil(np.sqrt(np.sqrt(len(all_names)))))\n",
    "        embed = nn.Embedding(len(all_names)+1, embed_dim)\n",
    "        for i in all_names:\n",
    "            self.master_dictionary[str(i)] = embed(torch.LongTensor([all_names.index(i)]).detach_())\n",
    "        return embed_dim\n",
    "            \n",
    "    def train_test_data_loading(self):\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = [], [], [], []\n",
    "        for cls in self.df['class'].unique():\n",
    "            for order in self.df[self.df['class']==cls]['order'].unique():\n",
    "                for family in self.df[(self.df['class']==cls) & (self.df['order']==order)]['family'].unique():\n",
    "                    for genus in self.df[(self.df['class']==cls) & (self.df['order']==order) & (self.df['family']==family)]['genus'].unique():\n",
    "                        for species in self.df[(self.df['class']==cls) & (self.df['order']==order) & (self.df['family']==family) & (self.df['genus']==genus)]['species_glc_id'].unique():\n",
    "                            path = self.path+\"train/\"+cls+\"/\"+order+\"/\"+family+\"/\"+genus+\"/\"+str(species)+\"/\"\n",
    "                            self.x_train.extend([path+i for i in os.listdir(path)])\n",
    "                            path = self.path+\"test/\"+cls+\"/\"+order+\"/\"+family+\"/\"+genus+\"/\"+str(species)+\"/\"\n",
    "                            self.x_test.extend([path+i for i in os.listdir(path)])\n",
    "        \n",
    "        np.random.shuffle(self.x_train)\n",
    "        np.random.shuffle(self.x_test)\n",
    "        \n",
    "        for im in self.x_train:\n",
    "            l = im.split(\"/\")\n",
    "            #c, o, f, g, s = self.master_dictionary[l[3]], self.master_dictionary[l[4]], self.master_dictionary[l[5]], self.master_dictionary[l[6]], self.master_dictionary[l[7]]\n",
    "            c = self.orders.index(l[4])\n",
    "            self.y_train.append(int(c))\n",
    "            \n",
    "        for im in self.x_test:\n",
    "            l = im.split(\"/\")\n",
    "            #c, o, f, g, s = self.master_dictionary[l[3]], self.master_dictionary[l[4]], self.master_dictionary[l[5]], self.master_dictionary[l[6]], self.master_dictionary[l[7]]\n",
    "            c = self.orders.index(l[4])\n",
    "            self.y_test.append(int(c))\n",
    "        \n",
    "    def ordered_call(self, root_dir, csv_file):\n",
    "        print(\"Creating the data preprocessing object and loading csv\")\n",
    "        self.init_load(root_dir, csv_file)\n",
    "        print(\"Done!\")\n",
    "        print(\"Creating unique mappings for labels\")\n",
    "        self.create_mappings_for_unique_labels()\n",
    "        print(\"Done!\")\n",
    "        print(\"Creating embeddings for all the names\")\n",
    "        out_dim = self.create_embedding()\n",
    "        print(\"Done!\")\n",
    "        print(\"Loading test and train image paths and corresponding labels\")\n",
    "        self.train_test_data_loading()\n",
    "        print(\"Done!\")\n",
    "        return out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T07:58:34.575902Z",
     "start_time": "2018-05-03T07:58:34.570849Z"
    }
   },
   "outputs": [],
   "source": [
    "class ShapesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, image_paths, labels):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.from_numpy(np.array(tif.imread(self.image_paths[idx])[:,17:-17,17:-17], dtype=np.float32)).detach()\n",
    "        label = self.labels[idx]\n",
    "        sample = {'image':image, 'label':label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T07:59:58.332454Z",
     "start_time": "2018-05-03T07:58:44.024872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the data preprocessing object and loading csv\n",
      "Done!\n",
      "Creating unique mappings for labels\n",
      "Done!\n",
      "Creating embeddings for all the names\n",
      "Done!\n",
      "Loading test and train image paths and corresponding labels\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data = Data_Preprocess()\n",
    "out_dims = data.ordered_call(root_dir=\"Data/Hierarchial Data/\", csv_file=\"occurrences_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T07:59:58.339114Z",
     "start_time": "2018-05-03T07:59:58.334221Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 100\n",
    "\n",
    "# Dataset\n",
    "train_dataset = ShapesDataset(image_paths=data.x_train, labels=data.y_train)\n",
    "\n",
    "test_dataset = ShapesDataset(image_paths=data.x_test, labels=data.y_test)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T07:59:58.779261Z",
     "start_time": "2018-05-03T07:59:58.340970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152980"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T08:00:03.612441Z",
     "start_time": "2018-05-03T08:00:03.609281Z"
    }
   },
   "outputs": [],
   "source": [
    "#batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T08:00:04.486410Z",
     "start_time": "2018-05-03T08:00:04.479262Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=33, out_channels=48, kernel_size=5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Max pool 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "     \n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=48, out_channels=128, kernel_size=3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Max pool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Convolution 3\n",
    "        self.cnn3 = nn.Conv2d(in_channels=128, out_channels=192, kernel_size=3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # Convolution 4\n",
    "        self.cnn4 = nn.Conv2d(in_channels=192, out_channels=192, kernel_size=3)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        # Convolution 5\n",
    "        self.cnn5 = nn.Conv2d(in_channels=192, out_channels=128, kernel_size=3)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        \n",
    "        # Max pool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully connected 1 (readout)\n",
    "        self.fc1 = nn.Linear(132*4*4,max(data.y_train)+1) \n",
    "        self.fc2 = nn.Linear(3800,max(data.y_train)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        # Max pool 1\n",
    "        out = self.maxpool1(out)\n",
    "        \n",
    "        # Convolution 2 \n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "#         # Convolution 3 \n",
    "#         out = self.cnn3(out)\n",
    "#         out = self.relu3(out)\n",
    "        \n",
    "        # Max pool 2 \n",
    "        out = self.maxpool2(out)\n",
    "        \n",
    "        # Resize\n",
    "        # Original size: (100, 32, 7, 7)\n",
    "        # out.size(0): 100\n",
    "        # New out size: (100, 32*7*7)\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        # Linear function (readout)\n",
    "        out = self.fc1(out)\n",
    "        #out = self.fc2(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T08:00:05.457972Z",
     "start_time": "2018-05-03T08:00:05.261632Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CNNModel()\n",
    "\n",
    "# #######################\n",
    "# #  USE GPU FOR MODEL  #\n",
    "# #######################\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T08:00:05.663561Z",
     "start_time": "2018-05-03T08:00:05.660455Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T08:00:06.133116Z",
     "start_time": "2018-05-03T08:00:06.127822Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T08:01:12.593129Z",
     "start_time": "2018-05-03T08:00:06.687616Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/home/miruna/keras/lib/python3.5/site-packages/ipykernel_launcher.py:67: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Loss: 28.538368225097656, Accuracy: 16.0\n",
      "Batch: 5, Loss: 7187507.0, Accuracy: 4.0\n",
      "Batch: 10, Loss: 3.978882074356079, Accuracy: 7.0\n",
      "Batch: 15, Loss: 4.015989303588867, Accuracy: 14.0\n",
      "Batch: 20, Loss: 4.011097431182861, Accuracy: 16.0\n",
      "Batch: 25, Loss: 8.707825660705566, Accuracy: 18.0\n",
      "Batch: 30, Loss: 4.007197380065918, Accuracy: 16.0\n",
      "Batch: 35, Loss: 3.999967336654663, Accuracy: 15.0\n",
      "Batch: 40, Loss: 4.001761436462402, Accuracy: 17.0\n",
      "Batch: 45, Loss: 3916904.25, Accuracy: 13.0\n",
      "Batch: 50, Loss: 3.9987430572509766, Accuracy: 15.0\n",
      "Batch: 55, Loss: 3.9959049224853516, Accuracy: 14.0\n",
      "Batch: 60, Loss: 3.986060857772827, Accuracy: 16.0\n",
      "Batch: 65, Loss: 3.9871528148651123, Accuracy: 17.0\n",
      "Batch: 70, Loss: 3.984562635421753, Accuracy: 17.0\n",
      "Batch: 75, Loss: 93.69624328613281, Accuracy: 11.0\n",
      "Batch: 80, Loss: 3.9767649173736572, Accuracy: 11.0\n",
      "Batch: 85, Loss: 3.9799492359161377, Accuracy: 15.0\n",
      "Batch: 90, Loss: 3.9741482734680176, Accuracy: 17.0\n",
      "Batch: 95, Loss: 3.973705768585205, Accuracy: 14.0\n",
      "Batch: 100, Loss: 3.958352565765381, Accuracy: 19.0\n",
      "Batch: 105, Loss: 3.9615814685821533, Accuracy: 16.0\n",
      "Batch: 110, Loss: 3.962961435317993, Accuracy: 9.0\n",
      "Batch: 115, Loss: 3.9526782035827637, Accuracy: 19.0\n",
      "Batch: 120, Loss: 3.9484972953796387, Accuracy: 23.0\n",
      "Batch: 125, Loss: 3.9445266723632812, Accuracy: 19.0\n",
      "Batch: 130, Loss: 3.94244384765625, Accuracy: 14.0\n",
      "Batch: 135, Loss: 3.93723726272583, Accuracy: 12.0\n",
      "Batch: 140, Loss: 3.9401535987854004, Accuracy: 16.0\n",
      "Batch: 145, Loss: 3.944575309753418, Accuracy: 15.0\n",
      "Batch: 150, Loss: 3.9281983375549316, Accuracy: 17.0\n",
      "Batch: 155, Loss: 3.92622709274292, Accuracy: 23.0\n",
      "Batch: 160, Loss: 3.925016403198242, Accuracy: 18.0\n",
      "Batch: 165, Loss: 3.9186229705810547, Accuracy: 13.0\n",
      "Batch: 170, Loss: 3.9215407371520996, Accuracy: 16.0\n",
      "Batch: 175, Loss: 3.9203476905822754, Accuracy: 16.0\n",
      "Batch: 180, Loss: 3.917670488357544, Accuracy: 17.0\n",
      "Batch: 185, Loss: 3.9284374713897705, Accuracy: 11.0\n",
      "Batch: 190, Loss: 3.901078462600708, Accuracy: 18.0\n",
      "Batch: 195, Loss: 3.9273064136505127, Accuracy: 10.0\n",
      "Batch: 200, Loss: 3.9084465503692627, Accuracy: 11.0\n",
      "Batch: 205, Loss: 3.885424852371216, Accuracy: 22.0\n",
      "Batch: 210, Loss: 3.907047986984253, Accuracy: 16.0\n",
      "Batch: 215, Loss: 3.9157555103302, Accuracy: 13.0\n",
      "Batch: 220, Loss: 3.8889381885528564, Accuracy: 18.0\n",
      "Batch: 225, Loss: 3.8864407539367676, Accuracy: 14.0\n",
      "Batch: 230, Loss: 3.870349645614624, Accuracy: 21.0\n",
      "Batch: 235, Loss: 3.872779130935669, Accuracy: 19.0\n",
      "Batch: 240, Loss: 3.8785128593444824, Accuracy: 13.0\n",
      "Batch: 245, Loss: 3.874735116958618, Accuracy: 20.0\n",
      "Batch: 250, Loss: 3.8641467094421387, Accuracy: 20.0\n",
      "Batch: 255, Loss: 3.855018377304077, Accuracy: 18.0\n",
      "Batch: 260, Loss: 3.877436876296997, Accuracy: 12.0\n",
      "Batch: 265, Loss: 3.8688745498657227, Accuracy: 7.0\n",
      "Batch: 270, Loss: 3.8584377765655518, Accuracy: 16.0\n",
      "Batch: 275, Loss: 3.854853630065918, Accuracy: 11.0\n",
      "Batch: 280, Loss: 3.850637912750244, Accuracy: 16.0\n",
      "Batch: 285, Loss: 3.847015142440796, Accuracy: 17.0\n",
      "Batch: 290, Loss: 3.850998640060425, Accuracy: 14.0\n",
      "Batch: 295, Loss: 3.8742666244506836, Accuracy: 12.0\n",
      "Batch: 300, Loss: 3.831183671951294, Accuracy: 15.0\n",
      "Batch: 305, Loss: 3.8558053970336914, Accuracy: 14.0\n",
      "Batch: 310, Loss: 3.86051869392395, Accuracy: 11.0\n",
      "Batch: 315, Loss: 3.819628953933716, Accuracy: 17.0\n",
      "Batch: 320, Loss: 3.862513780593872, Accuracy: 15.0\n",
      "Batch: 325, Loss: 3.8580024242401123, Accuracy: 16.0\n",
      "Batch: 330, Loss: 3.8449389934539795, Accuracy: 12.0\n",
      "Batch: 335, Loss: 3.8227245807647705, Accuracy: 17.0\n",
      "Batch: 340, Loss: 3.8377997875213623, Accuracy: 12.0\n",
      "Batch: 345, Loss: 3.8304812908172607, Accuracy: 16.0\n",
      "Batch: 350, Loss: 3.8388609886169434, Accuracy: 12.0\n",
      "Batch: 355, Loss: 3.827955961227417, Accuracy: 13.0\n",
      "Batch: 360, Loss: 3.807887554168701, Accuracy: 14.0\n",
      "Batch: 365, Loss: 3.7936947345733643, Accuracy: 18.0\n",
      "Batch: 370, Loss: 3.8016979694366455, Accuracy: 17.0\n",
      "Batch: 375, Loss: 3.768580675125122, Accuracy: 22.0\n",
      "Batch: 380, Loss: 3.8095695972442627, Accuracy: 13.0\n",
      "Batch: 385, Loss: 3.7788710594177246, Accuracy: 17.0\n",
      "Batch: 390, Loss: 3.7920191287994385, Accuracy: 16.0\n",
      "Batch: 395, Loss: 3.787465810775757, Accuracy: 16.0\n",
      "Batch: 400, Loss: 3.8402740955352783, Accuracy: 9.0\n",
      "Batch: 405, Loss: 3.780740976333618, Accuracy: 13.0\n",
      "Batch: 410, Loss: 3.7834463119506836, Accuracy: 12.0\n",
      "Batch: 415, Loss: 3.7835192680358887, Accuracy: 15.0\n",
      "Batch: 420, Loss: 3.7653441429138184, Accuracy: 20.0\n",
      "Batch: 425, Loss: 3.7737174034118652, Accuracy: 20.0\n",
      "Batch: 430, Loss: 3.770179033279419, Accuracy: 13.0\n",
      "Batch: 435, Loss: 3.7830328941345215, Accuracy: 16.0\n",
      "Batch: 440, Loss: 3.7885866165161133, Accuracy: 13.0\n",
      "Batch: 445, Loss: 3.764815330505371, Accuracy: 23.0\n",
      "Batch: 450, Loss: 3.7614188194274902, Accuracy: 18.0\n",
      "Batch: 455, Loss: 3.772120714187622, Accuracy: 17.0\n",
      "Batch: 460, Loss: 3.784050941467285, Accuracy: 13.0\n",
      "Batch: 465, Loss: 3.7531309127807617, Accuracy: 14.0\n",
      "Batch: 470, Loss: 3.756605863571167, Accuracy: 16.0\n",
      "Batch: 475, Loss: 3.777085542678833, Accuracy: 14.0\n",
      "Batch: 480, Loss: 3.755053758621216, Accuracy: 16.0\n",
      "Batch: 485, Loss: 3.7966015338897705, Accuracy: 11.0\n"
     ]
    }
   ],
   "source": [
    "#iter = 0\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        images=sample['image'].float()\n",
    "#         #######################\n",
    "#         #  USE GPU FOR MODEL  #\n",
    "#         #######################\n",
    "#         if torch.cuda.is_available():\n",
    "#             images = Variable(images.cuda())\n",
    "#             labels = Variable(sample['label'].cuda())\n",
    "#         else:\n",
    "        images = Variable(images)\n",
    "        labels = Variable(sample['label'])\n",
    "        \n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 5== 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            #for sample in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                #if torch.cuda.is_available():\n",
    "                    #images = Variable(sample['image'].cuda())\n",
    "                #else:\n",
    "                    #images = Variable(sample['image'])\n",
    "                \n",
    "            # Forward pass only to get logits/output\n",
    "            outputs = model(images)\n",
    "                \n",
    "            # Get predictions from the maximum value\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "            # Total number of labels\n",
    "            total += sample['label'].size(0)\n",
    "                \n",
    "#                 #######################\n",
    "#                 #  USE GPU FOR MODEL  #\n",
    "#                 #######################\n",
    "#                 # Total correct predictions\n",
    "#             if torch.cuda.is_available():\n",
    "#                 correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "#             else:\n",
    "            correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = float(100 * correct / total)\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Batch: {}, Loss: {}, Accuracy: {}'.format(i, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

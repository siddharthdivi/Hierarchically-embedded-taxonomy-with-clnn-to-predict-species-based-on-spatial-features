{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ShapesDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:].as_matrix()\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder='Shapes_hierarchial/Train/'\n",
    "# for classname in os.listdir(folder):\n",
    "#     for order in os.listdir(folder+str(classname)):\n",
    "#         for image in os.listdir(folder+str(classname)+'/'+str(order)):\n",
    "#             print(classname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i,s=load_images_from_folder('Shapes/Train/')\n",
    "# # c=0\n",
    "# # for j in range(len(s)):\n",
    "# #     if(s[j]=='Circle'):\n",
    "# #         c+=1\n",
    "# #print(i[2000],s[2000]) \n",
    "# #len(s)\n",
    "# np.array(i).shape\n",
    "# #len(i[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    clabel=[]\n",
    "    olabel=[]\n",
    "    for classname in os.listdir(folder):\n",
    "        for order in os.listdir(folder+str(classname)):\n",
    "            for image in os.listdir(folder+str(classname)+'/'+str(order)):\n",
    "            #img = Image.open(os.path.join(folder+str(filename)+'/'+str(image))).convert('LA')\n",
    "                img = cv2.imread(os.path.join(folder+str(classname)+'/'+str(order),image))\n",
    "                if img is not None:\n",
    "                    images.append(img.transpose((2, 0, 1)) )\n",
    "                    clabel.append(dic[str(classname)])\n",
    "                    olabel.append(dic[str(order)])\n",
    "    return images,clabel,olabel    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDataset(Dataset):\n",
    "\n",
    "    def __init__(self,root_dir, transform=None):\n",
    "        self.image=[]\n",
    "        self.clabel=[]\n",
    "        self.olabel=[]\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        cdic = dict((c, i) for i, c in enumerate(os.listdir(self.root_dir)))\n",
    "#         for filename in os.listdir(self.root_dir):\n",
    "#             for image in os.listdir(self.root_dir+str(filename)):\n",
    "#                 img = cv2.imread(os.path.join(self.root_dir+str(filename),image))\n",
    "#                 if img is not None:\n",
    "#                     self.image.append(img.transpose((2,0,1)))\n",
    "#                     self.shape.append(dic[str(filename)])\n",
    "        for classname in os.listdir(self.root_dir):\n",
    "            odic = dict((c, i) for i, c in enumerate(os.listdir(self.root_dir+str(classname))))\n",
    "            for order in os.listdir(self.root_dir+str(classname)):\n",
    "                for image in os.listdir(self.root_dir+str(classname)+'/'+str(order)):\n",
    "                #img = Image.open(os.path.join(folder+str(filename)+'/'+str(image))).convert('LA')\n",
    "                    img = cv2.imread(os.path.join(self.root_dir+str(classname)+'/'+str(order),image))\n",
    "                    if img is not None:\n",
    "                        self.image.append(img.transpose((2, 0, 1)) )\n",
    "                        self.clabel.append(cdic[str(classname)])\n",
    "                        self.olabel.append(odic[str(order)])\n",
    "    #return images,clabel,olabel                \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #if self.transform:\n",
    "            #sample = self.transform(sample) \n",
    "        self.image=np.array(self.image)\n",
    "        return torch.from_numpy(self.image[idx][0]).view(-1, 28,28),(self.clabel[idx]),(self.olabel[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 100\n",
    "\n",
    "# Dataset\n",
    "train_dataset = ShapesDataset(root_dir='Shapes_hierarchial/Train/',\n",
    "                               transform=transforms.ToTensor())\n",
    "\n",
    "test_dataset = ShapesDataset(root_dir='Shapes_hierarchial/Test/',\n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17168"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[15000][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[7000][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[7000][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LessThan5sides': 2, 'MoreThan5sides': 1, 'Nosides': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = dict((c, i) for i, c in enumerate(os.listdir('Shapes_hierarchial/Train/')))\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hexagon': 0, 'Pentagon': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = dict((c, i) for i, c in enumerate(os.listdir('Shapes_hierarchial/Train/MoreThan5sides')))\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[7000][0].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image=train_dataset[7000][0].numpy().reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fea0656c7f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(show_image,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train Loader is iterable\n",
    "import collections\n",
    "isinstance(train_loader,collections.Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(test_loader,collections.Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Max pool 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Branch 1-Class\n",
    "        self.cnnb1 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n",
    "        self.relub1 = nn.ReLU()\n",
    "        \n",
    "        # Max pool 1\n",
    "        self.maxpoolb1 = nn.MaxPool2d(kernel_size=2)\n",
    "     \n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Max pool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully connected 1 (readout)\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, 10) \n",
    "        self.fcb1 = nn.Linear(32 * 4 * 4, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        # Max pool 1\n",
    "        out = self.maxpool1(out)\n",
    "        \n",
    "        #Branching\n",
    "        class_label = self.cnnb1(out)\n",
    "        class_label = self.relub1(class_label)\n",
    "        class_label = self.maxpoolb1(class_label)\n",
    "        \n",
    "        # Convolution 2 \n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        # Max pool 2 \n",
    "        out = self.maxpool2(out)\n",
    "        \n",
    "        # Resize\n",
    "        # Original size: (100, 32, 7, 7)\n",
    "        # out.size(0): 100\n",
    "        # New out size: (100, 32*7*7)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        class_label = class_label.view(class_label.size(0), -1)\n",
    "\n",
    "        # Linear function (readout)\n",
    "        order_label = self.fc1(out)\n",
    "        class_label=self.fcb1(class_label)\n",
    "        \n",
    "        return class_label,order_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel()\n",
    "\n",
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, clabel,olabel) in enumerate(train_loader):\n",
    "        images=images.float()\n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            clabel = Variable(clabel.cuda())\n",
    "            olabel = Variable(olabel.cuda())\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            clabel = Variable(clabel)\n",
    "            olabel = Variable(olabel)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        cpred,opred = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        closs = criterion(cpred, clabel)\n",
    "        oloss = criterion(opred, olabel)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        closs.backward(retain_graph=True)\n",
    "        oloss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            ccorrect = 0\n",
    "            ctotal = 0\n",
    "            ocorrect=0\n",
    "            ototal=0\n",
    "            # Iterate through test dataset\n",
    "            for images, clabel,olabel in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                if torch.cuda.is_available():\n",
    "                    images = Variable(images.cuda())\n",
    "                else:\n",
    "                    images = Variable(images)\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                cpred,opred = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, cpredicted = torch.max(cpred.data, 1)\n",
    "                _, opredicted = torch.max(opred.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                ctotal += clabel.size(0)\n",
    "                ototal += olabel.size(0)\n",
    "                \n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    ccorrect += (cpredicted.cpu() == clabel.cpu()).sum()\n",
    "                    ocorrect += (opredicted.cpu() == olabel.cpu()).sum() \n",
    "                else:\n",
    "                    ccorrect += (cpredicted == clabel).sum()\n",
    "                    ocorrect += (opredicted == olabel).sum()\n",
    "            \n",
    "            caccuracy = 100 * ccorrect / ctotal\n",
    "            oaccuracy = 100 * ocorrect / ototal\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Class:Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, closs.data[0], caccuracy))\n",
    "            print('Order:Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, oloss.data[0], oaccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training settings\n",
    "# batch_size = 64\n",
    "\n",
    "# # MNIST Dataset\n",
    "# train_dataset = datasets.MNIST(root='./data/',\n",
    "#                                train=True,\n",
    "#                                transform=transforms.ToTensor(),\n",
    "#                                download=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data/',\n",
    "#                               train=False,\n",
    "#                               transform=transforms.ToTensor())\n",
    "\n",
    "# # Data Loader (Input Pipeline)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "#                                            batch_size=batch_size,\n",
    "#                                            shuffle=True)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "#                                           batch_size=batch_size,\n",
    "\n",
    "#                                           shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only 1-element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-b3aec57dde68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__float__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         raise TypeError(\"only 1-element tensors can be converted \"\n\u001b[0m\u001b[1;32m    402\u001b[0m                         \"to Python scalars\")\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only 1-element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "np.array(train_dataset.__getitem__(2)).shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Branched_CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(Branched_CNN, self).__init__()\n",
    "        self.branch1x1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch5x5_2 = nn.Conv2d(16, 24, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch3x3_2 = nn.Conv2d(16, 24, kernel_size=3, padding=1)\n",
    "        self.branch3x3_3 = nn.Conv2d(24, 24, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = nn.Conv2d(in_channels, 24, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x.float())\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x.float())\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x.float())\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "        branch3x3 = self.branch3x3_3(branch3x3)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3, branch_pool]\n",
    "        return torch.cat(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(88, 16, kernel_size=3)\n",
    "\n",
    "        self.network1 = Branched_CNN(in_channels=64)\n",
    "        self.network2 = Branched_CNN(in_channels=16)\n",
    "\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(2200,1600)\n",
    "        self.fc2 = nn.Linear(1600,800)\n",
    "        self.fc3 = nn.Linear(800,128)\n",
    "        self.fc4 = nn.Linear(128,16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = F.relu(self.mp(self.conv1(x.float())))\n",
    "       \n",
    "        x = self.network1(x.float())\n",
    "        x = F.relu(self.mp(self.conv2(x.float())))\n",
    "        x = self.network2(x.float())\n",
    "        x = x.view(in_size, -1)  # flatten the tensor\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Net(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(88, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (network1): Branched_CNN(\n",
       "    (branch1x1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch5x5_1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch5x5_2): Conv2d(16, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (branch3x3_1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch3x3_2): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (branch3x3_3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (branch_pool): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (network2): Branched_CNN(\n",
       "    (branch1x1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch5x5_1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch5x5_2): Conv2d(16, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (branch3x3_1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch3x3_2): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (branch3x3_3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (branch_pool): Conv2d(16, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (mp): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  (fc1): Linear(in_features=2200, out_features=1600, bias=True)\n",
       "  (fc2): Linear(in_features=1600, out_features=800, bias=True)\n",
       "  (fc3): Linear(in_features=800, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=16, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #print(target,\" :\",output)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data[0]\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.779853\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.754137\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.712965\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.673273\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.655825\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.616606\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.560194\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.488868\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.403643\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.375280\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.358360\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.321087\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.317182\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.296776\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.296909\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.313634\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.291624\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.342213\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.318429\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.329705\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.312308\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.303011\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.283953\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.293030\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.283916\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.293727\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.250108\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.260159\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.278714\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.244660\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.232038\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 2.240161\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.261198\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 2.237279\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.189768\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.141405\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.108947\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 2.064015\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 1.882684\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 1.811198\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.521808\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 1.535816\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 1.079516\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.956377\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.891215\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.940003\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.665240\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.934760\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.603871\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.662704\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.853190\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.532168\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.683599\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.709538\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.498611\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.541464\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.504234\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.628971\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.623419\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.562614\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.504955\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.524707\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.339873\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.679459\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.566385\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.378233\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.483869\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.651573\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.513004\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.669308\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.489272\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.407230\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.679767\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.521799\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.404014\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.413123\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.608718\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.432779\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.559012\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.495540\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.384009\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.416346\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.616838\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.581008\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.649109\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.536339\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.466868\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.288494\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.356024\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.704085\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.657869\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.711301\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.423917\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.281861\n",
      "\n",
      "Test set: Average loss: 0.4472, Accuracy: 8624/10000 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 2):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T16:09:57.191190Z",
     "start_time": "2018-04-20T16:09:56.534609Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import tifffile as tif\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from multiprocessing import Pool\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Reshape\n",
    "from collections import OrderedDict\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Permute\n",
    "from keras.models import load_model, save_model\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T03:35:15.243588Z",
     "start_time": "2018-04-20T03:35:14.989821Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, x_metadata, y_metadata, batch_size, crop_size):\n",
    "        self.x = x_metadata\n",
    "        self.y = y_metadata\n",
    "        self.batch_size = batch_size\n",
    "        self.cp = crop_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            \n",
    "        return np.array([np.transpose(np.array(tif.imread(file_name), dtype=int)/255.0,(1,2,0))\n",
    "                         [self.cp:-self.cp,self.cp:-self.cp,:] for file_name in batch_x]), np.array(batch_y)         \n",
    "\n",
    "class CNN_Model:\n",
    "    \n",
    "    def __init__(self, directory,class_name):\n",
    "        \n",
    "        self.onehot = {}\n",
    "        self.path = directory\n",
    "        \n",
    "        df = pd.read_csv(\"occurrences_train.csv\",low_memory=False)\n",
    "        with open(\"Data/hierarchy_data.pkl\",\"rb\") as f:\n",
    "            hd = pkl.load(f)\n",
    "        with open(\"Data/class_encoding.pkl\",\"rb\") as f:\n",
    "            self.classes = pkl.load(f)\n",
    "        with open(\"Data/order_encoding.pkl\",\"rb\") as f:\n",
    "            self.orders = pkl.load(f)\n",
    "        with open(\"Data/family_encoding.pkl\",\"rb\") as f:\n",
    "            self.families = pkl.load(f)\n",
    "        with open(\"Data/genus_encoding.pkl\",\"rb\") as f:\n",
    "            self.genuses = pkl.load(f)\n",
    "        with open(\"Data/specie_encoding.pkl\",\"rb\") as f:\n",
    "            self.species = pkl.load(f)\n",
    "\n",
    "        self.onehot_output()\n",
    "\n",
    "        self.train_pathdata_x = []\n",
    "        self.train_seq_y = []\n",
    "        self.test_pathdata_x = []\n",
    "        self.test_seq_y = []\n",
    "        \n",
    "        #for cls in hd.keys():\n",
    "        cls = class_name\n",
    "        \n",
    "        for order in hd[cls].keys():\n",
    "            for family in hd[cls][order].keys():\n",
    "                for genus in hd[cls][order][family].keys():\n",
    "                    for specie in hd[cls][order][family][genus]:\n",
    "                        for im in os.listdir(self.path+\"train/\"+str(self.classes[cls])+\"/\"+str(self.orders[order])\n",
    "                                             +\"/\"+str(self.families[family])+\"/\"+str(self.genuses[genus])+\"/\"+str(specie)):\n",
    "                            self.train_pathdata_x.append(self.path+\"train/\"+str(self.classes[cls])+\"/\"+str(self.orders[order])\n",
    "                                                         +\"/\"+str(self.families[family])+\"/\"+str(self.genuses[genus])+\"/\"+str(specie)+\"/\"\n",
    "                                                         +im)\n",
    "                            \n",
    "        #for cls in hd.keys():\n",
    "        \n",
    "        for order in hd[cls].keys():\n",
    "            for family in hd[cls][order].keys():\n",
    "                for genus in hd[cls][order][family].keys():\n",
    "                    for specie in hd[cls][order][family][genus]:\n",
    "                        for im in os.listdir(self.path+\"test/\"+str(self.classes[cls])+\"/\"+str(self.orders[order])\n",
    "                                             +\"/\"+str(self.families[family])+\"/\"+str(self.genuses[genus])+\"/\"+str(specie)):\n",
    "                            self.test_pathdata_x.append(self.path+\"test/\"+str(self.classes[cls])+\"/\"+str(self.orders[order])\n",
    "                                                         +\"/\"+str(self.families[family])+\"/\"+str(self.genuses[genus])+\"/\"+str(specie)+\"/\"\n",
    "                                                         +im)\n",
    "\n",
    "        np.random.shuffle(self.train_pathdata_x)\n",
    "        np.random.shuffle(self.test_pathdata_x)\n",
    "        \n",
    "        df = pd.read_csv(\"occurrences_train.csv\",low_memory=False)\n",
    "        df = df[['class','species_glc_id']]\n",
    "        \n",
    "        \n",
    "        for p in self.train_pathdata_x:\n",
    "            y = p.split(\"/\")\n",
    "            c = int(y[3])\n",
    "            o = int(y[4])\n",
    "            f = int(y[5])\n",
    "            g = int(y[6])\n",
    "            s = int(y[7])\n",
    "            d = list(df[df['class']==cls]['species_glc_id'].unique())\n",
    "            z = np.zeros((len(d)))\n",
    "            z[d.index(s)] = 1\n",
    "            self.train_seq_y.append(z)\n",
    "            \n",
    "        for p in self.test_pathdata_x:\n",
    "            y = p.split(\"/\")\n",
    "            c = int(y[3])\n",
    "            o = int(y[4])\n",
    "            f = int(y[5])\n",
    "            g = int(y[6])\n",
    "            s = int(y[7])\n",
    "            d = list(df[df['class']==cls]['species_glc_id'].unique())\n",
    "            z = np.zeros((len(d)))\n",
    "            z[d.index(s)] = 1\n",
    "            self.test_seq_y.append(z)\n",
    "        \n",
    "        print(np.array(self.train_pathdata_x).shape, np.array(self.train_seq_y).shape, np.array(self.test_pathdata_x).shape,np.array(self.test_seq_y).shape)\n",
    "        \n",
    "    def onehot_output(self):\n",
    "        for sp in self.species:\n",
    "            y = np.zeros(len(self.species))\n",
    "            y[list(self.species).index(sp)] = 1\n",
    "            self.onehot[sp] = y\n",
    "            \n",
    "    def model_create(self, dense_out, time_steps=5, batch_size=32):\n",
    "        \n",
    "        classifier = Sequential()\n",
    "        # Step 1 - Convolution\n",
    "        classifier.add(Conv2D(filters=64, kernel_size=(1, 1), input_shape = (32,32,33), activation = 'relu'))\n",
    "        classifier.add(Conv2D(filters=96, kernel_size=(3, 3), activation = 'relu'))\n",
    "        classifier.add(Conv2D(filters=128, kernel_size=(3, 3), activation = 'relu'))\n",
    "        classifier.add(Conv2D(filters=16, kernel_size=(5, 5), activation = 'relu'))\n",
    "        classifier.add(Conv2D(filters=32, kernel_size=(5, 5), activation = 'relu'))\n",
    "        #classifier.add(Conv2D(filters=, kernel_size=(2, 2), activation = 'relu'))\n",
    "        classifier.add(MaxPool2D(pool_size = (2, 2)))\n",
    "        # Step 3 - Flattening\n",
    "        classifier.add(Flatten())\n",
    "        # Step 4 - Full connection\n",
    "        classifier.add(Dense(128, activation = 'relu'))\n",
    "        #classifier.add(Dense(128, activation = 'tanh'))\n",
    "        classifier.add(Dense(dense_out, activation = 'softmax'))\n",
    "        # Compiling the CNN\n",
    "        if(dense_out >= 300):\n",
    "            classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "        elif(dense_out == 1):\n",
    "            classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "        else:\n",
    "            classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "        classifier.summary()\n",
    "        return classifier\n",
    "    \n",
    "    def fit_generator(self, class_name, num_epochs=10, batch_size=32, crop_size=16, time_steps=5):        \n",
    "        print(\"Class : \", class_name)\n",
    "        try:\n",
    "            classifier = load_model(\"Code/Models/\"+str(class_name)+\".h5\")\n",
    "        except:\n",
    "            print (\"-------------------------------------------------------\")\n",
    "            print(\"Training\")\n",
    "            classifier = self.model_create(dense_out=np.array(self.train_seq_y).shape[1], time_steps=time_steps, batch_size=batch_size)\n",
    "            train_data = ImageDataGenerator(self.train_pathdata_x, self.train_seq_y, batch_size, crop_size)\n",
    "            history = classifier.fit_generator(train_data, epochs=num_epochs, use_multiprocessing=True,shuffle=True)\n",
    "            classifier.save(\"Code/Models/\"+str(class_name)+\".h5\")\n",
    "            \n",
    "        print (\"---------------------------------------------------\")    \n",
    "        print(\"Testing\")\n",
    "        test_data = ImageDataGenerator(self.test_pathdata_x, self.test_seq_y, batch_size, crop_size)\n",
    "        scores = classifier.evaluate_generator(test_data, use_multiprocessing=True)\n",
    "        print(\"Loss : \", scores[0])\n",
    "        print(\"Accuracy : \", scores[1])\n",
    "        print (\"-------------------------------------------------------\")\n",
    "        del classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T15:00:17.492243Z",
     "start_time": "2018-04-20T15:00:17.485094Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1270,) (1270, 39) (510,) (510, 39)\n",
      "Class :  Pinopsida\n",
      "---------------------------------------------------\n",
      "Testing\n",
      "Loss :  2.7298653967240276\n",
      "Accuracy :  0.2823529484517434\n",
      "-------------------------------------------------------\n",
      "(188,) (188, 9) (100,) (100, 9)\n",
      "Class :  Lycopodiopsida\n",
      "-------------------------------------------------------\n",
      "Training\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        2176      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 96)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 128)       110720    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 16)        51216     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 20, 20, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               409728    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 643,225\n",
      "Trainable params: 643,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "7/7 [==============================] - 2s 305ms/step - loss: 1.4921 - acc: 0.6986\n",
      "Epoch 2/25\n",
      "7/7 [==============================] - 1s 157ms/step - loss: 0.9114 - acc: 0.8049\n",
      "Epoch 3/25\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.7033 - acc: 0.8049\n",
      "Epoch 4/25\n",
      "7/7 [==============================] - 1s 157ms/step - loss: 0.7226 - acc: 0.8194\n",
      "Epoch 5/25\n",
      "7/7 [==============================] - 1s 170ms/step - loss: 0.7212 - acc: 0.8146\n",
      "Epoch 6/25\n",
      "7/7 [==============================] - 1s 157ms/step - loss: 0.6840 - acc: 0.8291\n",
      "Epoch 7/25\n",
      "7/7 [==============================] - 1s 158ms/step - loss: 0.6021 - acc: 0.8406\n",
      "Epoch 8/25\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.5740 - acc: 0.8454\n",
      "Epoch 9/25\n",
      "7/7 [==============================] - 1s 147ms/step - loss: 0.5176 - acc: 0.8551\n",
      "Epoch 10/25\n",
      "7/7 [==============================] - 1s 161ms/step - loss: 0.4900 - acc: 0.8647\n",
      "Epoch 11/25\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.4687 - acc: 0.8647\n",
      "Epoch 12/25\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.4331 - acc: 0.8599\n",
      "Epoch 13/25\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.4625 - acc: 0.8792\n",
      "Epoch 14/25\n",
      "7/7 [==============================] - 1s 150ms/step - loss: 0.4807 - acc: 0.8647\n",
      "Epoch 15/25\n",
      "7/7 [==============================] - 1s 157ms/step - loss: 0.4323 - acc: 0.8744\n",
      "Epoch 16/25\n",
      "7/7 [==============================] - 1s 164ms/step - loss: 0.3773 - acc: 0.8744\n",
      "Epoch 17/25\n",
      "7/7 [==============================] - 1s 159ms/step - loss: 0.3378 - acc: 0.8985\n",
      "Epoch 18/25\n",
      "7/7 [==============================] - 1s 163ms/step - loss: 0.3620 - acc: 0.8744\n",
      "Epoch 19/25\n",
      "7/7 [==============================] - 1s 154ms/step - loss: 0.3222 - acc: 0.8985\n",
      "Epoch 20/25\n",
      "7/7 [==============================] - 1s 157ms/step - loss: 0.3329 - acc: 0.8937\n",
      "Epoch 21/25\n",
      "7/7 [==============================] - 1s 166ms/step - loss: 0.3811 - acc: 0.8744\n",
      "Epoch 22/25\n",
      "7/7 [==============================] - 1s 164ms/step - loss: 0.3496 - acc: 0.8792\n",
      "Epoch 23/25\n",
      "7/7 [==============================] - 1s 158ms/step - loss: 0.3333 - acc: 0.8840\n",
      "Epoch 24/25\n",
      "7/7 [==============================] - 1s 164ms/step - loss: 0.3452 - acc: 0.8985\n",
      "Epoch 25/25\n",
      "7/7 [==============================] - 1s 164ms/step - loss: 0.2699 - acc: 0.9227\n",
      "---------------------------------------------------\n",
      "Testing\n",
      "Loss :  1.399360603094101\n",
      "Accuracy :  0.7400000154972076\n",
      "-------------------------------------------------------\n",
      "(319,) (319, 8) (152,) (152, 8)\n",
      "Class :  Equisetopsida\n",
      "-------------------------------------------------------\n",
      "Training\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 64)        2176      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 30, 96)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 128)       110720    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 24, 24, 16)        51216     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 20, 20, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               409728    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 643,096\n",
      "Trainable params: 643,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 2s 166ms/step - loss: 1.8030 - acc: 0.3652\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 1.6853 - acc: 0.3986\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 2s 166ms/step - loss: 1.7742 - acc: 0.3986\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 2s 165ms/step - loss: 1.6818 - acc: 0.4078\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 2s 156ms/step - loss: 1.5978 - acc: 0.4582\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 1.5192 - acc: 0.4551\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 2s 159ms/step - loss: 1.4689 - acc: 0.4582\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 2s 156ms/step - loss: 1.4768 - acc: 0.4703\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 1.4363 - acc: 0.4750\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 2s 160ms/step - loss: 1.4098 - acc: 0.4734\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 2s 158ms/step - loss: 1.5445 - acc: 0.4794\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 2s 160ms/step - loss: 1.4599 - acc: 0.4444\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 2s 158ms/step - loss: 1.3806 - acc: 0.5025\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 2s 167ms/step - loss: 1.3091 - acc: 0.5084\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 1.2869 - acc: 0.5359\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 2s 157ms/step - loss: 1.2821 - acc: 0.5359\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 2s 158ms/step - loss: 1.2397 - acc: 0.5361\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 1.1841 - acc: 0.5665\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 2s 156ms/step - loss: 1.1835 - acc: 0.5697\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 2s 158ms/step - loss: 1.1707 - acc: 0.5450\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 1.1138 - acc: 0.6242\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 2s 160ms/step - loss: 1.1787 - acc: 0.6137\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 2s 158ms/step - loss: 1.0742 - acc: 0.6090\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 1.0784 - acc: 0.6076\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 2s 158ms/step - loss: 1.0627 - acc: 0.6076\n",
      "---------------------------------------------------\n",
      "Testing\n",
      "Loss :  1.8404089690823304\n",
      "Accuracy :  0.41447369224931063\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ea9ffb6cded8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data/Hierarchial Data/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-000de68ec68f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, class_name)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'species_glc_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    724\u001b[0m                 \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 raise TypeError('Could not compare %s type with Series'\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    646\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"Data/class_encoding.pkl\",\"rb\") as f:\n",
    "    classes = pkl.load(f)\n",
    "\n",
    "classes_to_names = {}\n",
    "for key,val in classes.items():\n",
    "    classes_to_names[val] = key\n",
    "    \n",
    "for cls in list(classes.keys()):\n",
    "    ob = CNN_Model(\"Data/Hierarchial Data/\",cls)\n",
    "    ob.fit_generator(cls, num_epochs=25, batch_size=30, time_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING.\n",
    "counter=0\n",
    "nparray = np.zeros(shape=(num_test_images,33,32,32),dtype=np.float32)\n",
    "for i in #path of test images.\n",
    "    #Crop each image to a size of 32 x 32.\n",
    "    nparray[counter] = crop_center(tiff.imread(i),32,32)/255.0\n",
    "    counter+=1\n",
    "    \n",
    "#Now make predictions, using the initial class prediction model.\n",
    "class_predictor = load_model('CNN_1.h5')\n",
    "yPred = class_predictor.predict(nparray)\n",
    "#Now, based on yPred call each of the corresponding models.\n",
    "final_pred = []\n",
    "for i in range(yPred.shape[0]):\n",
    "    if(yPred[i]==0):\n",
    "        model = load_model(classes_to_names[yPred[i]]+\".h5\")\n",
    "        final_pred.append(model.predict(nparray[i]))\n",
    "    elif(yPred[i]==1):\n",
    "        model = load_model(classes_to_names[yPred[i]]+\".h5\")\n",
    "        final_pred.append(model.predict(nparray[i]))\n",
    "    elif(yPred[i]==2):\n",
    "        model = load_model(classes_to_names[yPred[i]]+\".h5\")\n",
    "        final_pred.append(model.predict(nparray[i]))\n",
    "    elif(yPred[i]==3):\n",
    "        model = load_model(classes_to_names[yPred[i]]+\".h5\")\n",
    "        final_pred.append(model.predict(nparray[i]))\n",
    "    elif(yPred[i]==4):\n",
    "        model = load_model(classes_to_names[yPred[i]]+\".h5\")\n",
    "        final_pred.append(model.predict(nparray[i]))\n",
    "    elif(yPred[i]==5):\n",
    "        model = load_model(classes_to_names[yPred[i]]+\".h5\")\n",
    "        final_pred.append(model.predict(nparray[i]))\n",
    "    elif(yPred[i]==6):\n",
    "        model = load_model(classes_to_names[yPred[i]]+\".h5\")\n",
    "        final_pred.append(model.predict(nparray[i]))\n",
    "    elif(yPred[i]==7):\n",
    "        model = load_model(classes_to_names[yPred[i]]+\".h5\")\n",
    "        final_pred.append(model.predict(nparray[i]))\n",
    "    elif(yPred[i]==8):\n",
    "        model = load_model(classes_to_names[yPred[i]]+\".h5\")\n",
    "        final_pred.append(model.predict(nparray[i]))\n",
    "    elif(yPred[i]==9):\n",
    "        model = load_model(classes_to_names[yPred[i]]+\".h5\")\n",
    "        final_pred.append(model.predict(nparray[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ob.fit_generator(num_epochs=10, batch_size=30, time_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T05:58:04.707045Z",
     "start_time": "2018-05-02T05:58:04.695526Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from keras import *\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import BatchNormalization,Embedding,Dense,Dropout,Conv2D,LSTM,MaxPooling2D,Flatten,MaxPooling1D,TimeDistributed,Reshape\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os \n",
    "import tifffile as tiff\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.utils import np_utils,Sequence\n",
    "np.random.seed(7)\n",
    "\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, x_metadata, y_metadata, batch_size, crop_size):\n",
    "        self.x = x_metadata\n",
    "        self.y = y_metadata\n",
    "        self.batch_size = batch_size\n",
    "        self.cp = crop_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        arr = []\n",
    "        for file_name in batch_x:\n",
    "            arr.append(np.array(np.array(tif.imread(file_name), dtype=int)/255.0)[self.cp:-self.cp,self.cp:-self.cp,:])\n",
    "            \n",
    "        return np.array(arr), np.array(batch_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T04:40:26.244838Z",
     "start_time": "2018-05-02T04:40:25.984973Z"
    }
   },
   "outputs": [],
   "source": [
    "def crop_center(img,cropx,cropy):\n",
    "    nparray = np.zeros((img.shape[0],img.shape[1]/2,img.shape[2]/2),dtype=np.float32)\n",
    "    for i in range(img.shape[0]):\n",
    "        y,x = img.shape[1],img.shape[2]\n",
    "        startx = x//2-(cropx//2)\n",
    "        starty = y//2-(cropy//2)    \n",
    "        nparray[i] = img[i][starty:starty+cropy,startx:startx+cropx]\n",
    "    return nparray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T05:31:15.029853Z",
     "start_time": "2018-05-02T05:30:36.287122Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/patchTrain/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3031fe438d39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data/patchTrain/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data/patchTrain/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mnparray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop_center\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data/patchTrain/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/patchTrain/'"
     ]
    }
   ],
   "source": [
    "nparray = np.zeros(shape=(256*10,33,32,32),dtype=np.float32)\n",
    "indices = []\n",
    "counter=0\n",
    "for j in os.listdir(\"Data/patchTrain/\")[:10]:\n",
    "    for i in os.listdir(\"Data/patchTrain/\"+str(j)+\"/\"):\n",
    "        nparray[counter] = crop_center(tiff.imread(\"Data/patchTrain/\"+j+\"/\"+i),32,32)/255.0\n",
    "        indices += [int(i.split(\"_\")[1].split(\".\")[0])]\n",
    "        counter+=1\n",
    "\n",
    "df = pd.read_csv(\"occurrences_train.csv\",sep=';', error_bad_lines=False)\n",
    "df = df[[\"class\",\"order\",\"family\",\"genus\",\"species\"]]\n",
    "df = df.iloc[indices,:]\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder = encoder.fit(df['class'])\n",
    "df ['class'] = encoder.transform(df['class'])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder = encoder.fit(df['order'])\n",
    "df ['order'] = encoder.transform(df['order'])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder = encoder.fit(df['family'])\n",
    "df ['family'] = encoder.transform(df['family'])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder = encoder.fit(df['genus'])\n",
    "df ['genus'] = encoder.transform(df['genus'])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder = encoder.fit(df['species'])\n",
    "df ['species'] = encoder.transform(df['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T05:25:35.732188Z",
     "start_time": "2018-05-02T05:25:35.550665Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T10:50:14.091149Z",
     "start_time": "2018-05-02T10:50:13.075281Z"
    }
   },
   "outputs": [],
   "source": [
    "input_arr = np.zeros((df.shape[0],1))\n",
    "for i in range(df.shape[0]):\n",
    "    for j in range(df.iloc[i,:-4].shape[0]):x\n",
    "        input_arr[i][j] = df.iloc[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T10:50:17.688354Z",
     "start_time": "2018-05-02T10:50:17.681645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       ...,\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:06:33.325981Z",
     "start_time": "2018-05-02T15:04:48.022275Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception KeyboardInterrupt in <function _remove at 0x7fbdb3ace8c0> ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_30 (Embedding)     (None, 1, 32)             16000     \n",
      "_________________________________________________________________\n",
      "lstm_79 (LSTM)               (None, 1, 1)              136       \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 1, 1)              0         \n",
      "_________________________________________________________________\n",
      "lstm_80 (LSTM)               (None, 1, 4)              96        \n",
      "=================================================================\n",
      "Total params: 16,232\n",
      "Trainable params: 16,232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'backend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-273-852896e1084e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, sample_weight_mode, weighted_metrics, **kwargs)\u001b[0m\n\u001b[1;32m    782\u001b[0m                            \u001b[0msample_weight_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m                            \u001b[0mweighted_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m                            **kwargs)\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    922\u001b[0m                         \u001b[0mappend_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_weighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mhandle_metrics\u001b[0;34m(metrics, weights)\u001b[0m\n\u001b[1;32m    919\u001b[0m                             metric_result = weighted_metric_fn(y_true, y_pred,\n\u001b[1;32m    920\u001b[0m                                                                \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                                                                mask=masks[i])\n\u001b[0m\u001b[1;32m    922\u001b[0m                         \u001b[0mappend_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \"\"\"\n\u001b[1;32m    449\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-273-852896e1084e>\u001b[0m in \u001b[0;36mf1\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;31m#return 2*((precision*recall)/(precision+recall+tf.backend.keras.epsilon))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'backend'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        '''\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        '''\n",
    "        return tf.metrics.recall(y_true,y_pred)\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        '''\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        '''\n",
    "        return tf.metrics.precision(y_true,y_pred)\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return tf.multiply ( tf.constant(2), tf.divide (tf.add(precision,recall),tf.add(precision,recall,tf.backend.keras.epsilon) ) )\n",
    "    #return 2*((precision*recall)/(precision+recall+tf.backend.keras.epsilon))\n",
    "\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(Embedding(500,32,input_length=1))\n",
    "model.add(LSTM(1,input_shape=input_arr.shape[1:],return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(4,return_sequences=True))\n",
    "model.summary()\n",
    "model.compile(loss='mae',optimizer='Adam',metrics=['accuracy',f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T10:51:14.059454Z",
     "start_time": "2018-05-02T10:51:14.051780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       ...,\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T10:51:14.450522Z",
     "start_time": "2018-05-02T10:51:14.376206Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected lstm_59 to have 3 dimensions, but got array with shape (2560, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-b817d8c38dd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_arr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1383\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1384\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    130\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected lstm_59 to have 3 dimensions, but got array with shape (2560, 4)"
     ]
    }
   ],
   "source": [
    "model.fit(input_arr,df.values[:,1:],batch_size=32,epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T07:16:23.209869Z",
     "start_time": "2018-05-02T07:16:23.199688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.]],\n",
       "\n",
       "       [[3.]],\n",
       "\n",
       "       [[3.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[3.]],\n",
       "\n",
       "       [[3.]],\n",
       "\n",
       "       [[3.]]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_arr[:,:,0][:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:45:53.124671Z",
     "start_time": "2018-05-02T15:45:52.640753Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        '''\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        '''\n",
    "        return tf.metrics.recall(y_true,y_pred)\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        '''\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        '''\n",
    "        return tf.metrics.precision(y_true,y_pred)\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return tf.multiply ( tf.constant(2.0), tf.divide (tf.add(precision,recall),tf.add(precision,recall) ) )\n",
    "    #return 2*((precision*recall)/(precision+recall+tf.backend.keras.epsilon))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32,kernel_size=(2,2),activation='relu',input_shape=(33,32,32)))\n",
    "model.add(Conv2D(filters=64,kernel_size=(4,4),activation='relu'))\n",
    "model.add(Conv2D(filters=128,kernel_size=(6,6),activation='relu'))\n",
    "model.add(Conv2D(filters=256,kernel_size=(10,10),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Reshape((7*7,256)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(4))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4))\n",
    "model.compile(loss='mae',optimizer='Adam',metrics=['accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T07:16:31.438023Z",
     "start_time": "2018-05-02T07:16:31.369584Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected lstm_40_input to have shape (None, 1, 4) but got array with shape (2560, 1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-aa777fd90dfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1694\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    142\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected lstm_40_input to have shape (None, 1, 4) but got array with shape (2560, 1, 1)"
     ]
    }
   ],
   "source": [
    "model.predict(input_arr[:,:,0][:,:,np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:45:53.140051Z",
     "start_time": "2018-05-02T15:45:53.128176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 31, 32)        4128      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 28, 64)        32832     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 23, 128)       295040    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 14, 256)       3277056   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 49, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 49, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 4)                 4176      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 20        \n",
      "=================================================================\n",
      "Total params: 3,613,252\n",
      "Trainable params: 3,613,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T04:51:12.705946Z",
     "start_time": "2018-05-02T04:51:12.693617Z"
    }
   },
   "outputs": [],
   "source": [
    "y_coarse = pd.get_dummies(df.iloc[:,0])\n",
    "y_fine = pd.get_dummies(df.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T15:02:11.473550Z",
     "start_time": "2018-04-24T15:02:11.203470Z"
    }
   },
   "outputs": [],
   "source": [
    "img_input = Input(shape=(33,32,32), name='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-24T15:06:46.134Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:42: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., name=\"medium_dynamic\", inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2560/2560 [==============================] - 287s - loss: 5.7731 - c1_predictions_cifar10_loss: 1.7878 - predictions_cifar10_loss: 3.9854 - c1_predictions_cifar10_acc: 0.4238 - predictions_cifar10_acc: 0.1367   \n",
      "Epoch 2/100\n",
      "2560/2560 [==============================] - 238s - loss: 4.6347 - c1_predictions_cifar10_loss: 1.1482 - predictions_cifar10_loss: 3.4865 - c1_predictions_cifar10_acc: 0.6430 - predictions_cifar10_acc: 0.1625   \n",
      "Epoch 3/100\n",
      "2560/2560 [==============================] - 232s - loss: 4.1609 - c1_predictions_cifar10_loss: 0.9090 - predictions_cifar10_loss: 3.2519 - c1_predictions_cifar10_acc: 0.7406 - predictions_cifar10_acc: 0.1809   \n",
      "Epoch 4/100\n",
      "2560/2560 [==============================] - 234s - loss: 3.9104 - c1_predictions_cifar10_loss: 0.8299 - predictions_cifar10_loss: 3.0804 - c1_predictions_cifar10_acc: 0.7723 - predictions_cifar10_acc: 0.1789   \n",
      "Epoch 5/100\n",
      "2560/2560 [==============================] - 233s - loss: 3.8121 - c1_predictions_cifar10_loss: 0.7961 - predictions_cifar10_loss: 3.0160 - c1_predictions_cifar10_acc: 0.7750 - predictions_cifar10_acc: 0.1891   \n",
      "Epoch 6/100\n",
      "2560/2560 [==============================] - 236s - loss: 3.6211 - c1_predictions_cifar10_loss: 0.7476 - predictions_cifar10_loss: 2.8736 - c1_predictions_cifar10_acc: 0.7863 - predictions_cifar10_acc: 0.2031   \n",
      "Epoch 7/100\n",
      "2560/2560 [==============================] - 260s - loss: 3.5685 - c1_predictions_cifar10_loss: 0.7179 - predictions_cifar10_loss: 2.8506 - c1_predictions_cifar10_acc: 0.7871 - predictions_cifar10_acc: 0.1961   \n",
      "Epoch 8/100\n",
      "2560/2560 [==============================] - 257s - loss: 3.5498 - c1_predictions_cifar10_loss: 0.7037 - predictions_cifar10_loss: 2.8462 - c1_predictions_cifar10_acc: 0.7875 - predictions_cifar10_acc: 0.1973   \n",
      "Epoch 9/100\n",
      "2560/2560 [==============================] - 271s - loss: 3.4783 - c1_predictions_cifar10_loss: 0.6956 - predictions_cifar10_loss: 2.7827 - c1_predictions_cifar10_acc: 0.7898 - predictions_cifar10_acc: 0.1977   \n",
      "Epoch 10/100\n",
      "2560/2560 [==============================] - 260s - loss: 3.5445 - c1_predictions_cifar10_loss: 0.7024 - predictions_cifar10_loss: 2.8421 - c1_predictions_cifar10_acc: 0.7918 - predictions_cifar10_acc: 0.1945   \n",
      "Epoch 11/100\n",
      "2560/2560 [==============================] - 234s - loss: 3.4182 - c1_predictions_cifar10_loss: 0.6788 - predictions_cifar10_loss: 2.7394 - c1_predictions_cifar10_acc: 0.7926 - predictions_cifar10_acc: 0.2117   \n",
      "Epoch 12/100\n",
      "2560/2560 [==============================] - 233s - loss: 3.4133 - c1_predictions_cifar10_loss: 0.6563 - predictions_cifar10_loss: 2.7571 - c1_predictions_cifar10_acc: 0.8012 - predictions_cifar10_acc: 0.2090   \n",
      "Epoch 13/100\n",
      "2560/2560 [==============================] - 233s - loss: 3.2645 - c1_predictions_cifar10_loss: 0.6320 - predictions_cifar10_loss: 2.6325 - c1_predictions_cifar10_acc: 0.8098 - predictions_cifar10_acc: 0.2273   \n",
      "Epoch 14/100\n",
      "2560/2560 [==============================] - 233s - loss: 3.2247 - c1_predictions_cifar10_loss: 0.6047 - predictions_cifar10_loss: 2.6200 - c1_predictions_cifar10_acc: 0.8102 - predictions_cifar10_acc: 0.2211   \n",
      "Epoch 15/100\n",
      "2560/2560 [==============================] - 232s - loss: 3.2232 - c1_predictions_cifar10_loss: 0.6299 - predictions_cifar10_loss: 2.5933 - c1_predictions_cifar10_acc: 0.8047 - predictions_cifar10_acc: 0.2270   \n",
      "Epoch 16/100\n",
      "2560/2560 [==============================] - 248s - loss: 3.1302 - c1_predictions_cifar10_loss: 0.5924 - predictions_cifar10_loss: 2.5378 - c1_predictions_cifar10_acc: 0.8117 - predictions_cifar10_acc: 0.2473   \n",
      "Epoch 17/100\n",
      "2560/2560 [==============================] - 248s - loss: 3.2062 - c1_predictions_cifar10_loss: 0.6044 - predictions_cifar10_loss: 2.6018 - c1_predictions_cifar10_acc: 0.8117 - predictions_cifar10_acc: 0.2297   \n",
      "Epoch 18/100\n",
      "2560/2560 [==============================] - 233s - loss: 3.1104 - c1_predictions_cifar10_loss: 0.5980 - predictions_cifar10_loss: 2.5124 - c1_predictions_cifar10_acc: 0.8090 - predictions_cifar10_acc: 0.2523   \n",
      "Epoch 19/100\n",
      "2560/2560 [==============================] - 233s - loss: 3.1009 - c1_predictions_cifar10_loss: 0.5948 - predictions_cifar10_loss: 2.5061 - c1_predictions_cifar10_acc: 0.8047 - predictions_cifar10_acc: 0.2629   \n",
      "Epoch 20/100\n",
      "2560/2560 [==============================] - 233s - loss: 3.0637 - c1_predictions_cifar10_loss: 0.5897 - predictions_cifar10_loss: 2.4740 - c1_predictions_cifar10_acc: 0.8094 - predictions_cifar10_acc: 0.2496   \n",
      "Epoch 21/100\n",
      "2560/2560 [==============================] - 233s - loss: 3.0630 - c1_predictions_cifar10_loss: 0.5609 - predictions_cifar10_loss: 2.5021 - c1_predictions_cifar10_acc: 0.8168 - predictions_cifar10_acc: 0.2723   \n",
      "Epoch 22/100\n",
      "2560/2560 [==============================] - 239s - loss: 3.0265 - c1_predictions_cifar10_loss: 0.5632 - predictions_cifar10_loss: 2.4633 - c1_predictions_cifar10_acc: 0.8105 - predictions_cifar10_acc: 0.2629   \n",
      "Epoch 23/100\n",
      "2560/2560 [==============================] - 256s - loss: 2.9492 - c1_predictions_cifar10_loss: 0.5504 - predictions_cifar10_loss: 2.3988 - c1_predictions_cifar10_acc: 0.8105 - predictions_cifar10_acc: 0.2707   \n",
      "Epoch 24/100\n",
      "2560/2560 [==============================] - 278s - loss: 2.8701 - c1_predictions_cifar10_loss: 0.5224 - predictions_cifar10_loss: 2.3477 - c1_predictions_cifar10_acc: 0.8266 - predictions_cifar10_acc: 0.2980   \n",
      "Epoch 25/100\n",
      "2560/2560 [==============================] - 253s - loss: 2.8998 - c1_predictions_cifar10_loss: 0.5464 - predictions_cifar10_loss: 2.3534 - c1_predictions_cifar10_acc: 0.8180 - predictions_cifar10_acc: 0.2902   \n",
      "Epoch 26/100\n",
      "2560/2560 [==============================] - 232s - loss: 2.9078 - c1_predictions_cifar10_loss: 0.5288 - predictions_cifar10_loss: 2.3790 - c1_predictions_cifar10_acc: 0.8266 - predictions_cifar10_acc: 0.2918   \n",
      "Epoch 27/100\n",
      "2560/2560 [==============================] - 233s - loss: 2.8504 - c1_predictions_cifar10_loss: 0.5174 - predictions_cifar10_loss: 2.3330 - c1_predictions_cifar10_acc: 0.8168 - predictions_cifar10_acc: 0.3047   \n",
      "Epoch 28/100\n",
      "1216/2560 [=============>................] - ETA: 122s - loss: 2.7919 - c1_predictions_cifar10_loss: 0.5023 - predictions_cifar10_loss: 2.2896 - c1_predictions_cifar10_acc: 0.8306 - predictions_cifar10_acc: 0.3051"
     ]
    }
   ],
   "source": [
    "#--- block 1 ---\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "#--- block 2 ---\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "#--- coarse 1 branch ---\n",
    "c_1_bch = Flatten(name='c1_flatten')(x)\n",
    "c_1_bch = Dense(256, activation='relu', name='c1_fc_cifar10_1')(c_1_bch)\n",
    "c_1_bch = BatchNormalization()(c_1_bch)\n",
    "c_1_bch = Dropout(0.5)(c_1_bch)\n",
    "c_1_bch = Dense(256, activation='relu', name='c1_fc2')(c_1_bch)\n",
    "c_1_bch = BatchNormalization()(c_1_bch)\n",
    "c_1_bch = Dropout(0.5)(c_1_bch)\n",
    "c_1_pred = Dense(5, activation='softmax', name='c1_predictions_cifar10')(c_1_bch)\n",
    "\n",
    "#--- block 4 ---\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "#--- fine block ---\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(1024, activation='relu', name='fc_cifar10_1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation='relu', name='fc2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "fine_pred = Dense(27, activation='softmax', name='predictions_cifar10')(x)\n",
    "\n",
    "model = Model(input=img_input, output=[c_1_pred, fine_pred], name='medium_dynamic')\n",
    "\n",
    "#----------------------- compile and fit ---------------------------\n",
    "sgd = optimizers.SGD(lr=0.003, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='Adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(nparray, [ y_coarse.values , y_fine.values ],\n",
    "          batch_size=32,\n",
    "          epochs=100,\n",
    "          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T15:06:35.776914Z",
     "start_time": "2018-04-24T15:06:35.771017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_coarse.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:45:54.925671Z",
     "start_time": "2018-05-02T15:45:54.918571Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4182e5499ff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-02T15:45:57.540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2560/2560 [==============================] - 487s - loss: 58.5739 - acc: 0.6059 - categorical_accuracy: 0.6059   \n",
      "Epoch 2/1000\n",
      "2560/2560 [==============================] - 436s - loss: 58.2572 - acc: 0.6355 - categorical_accuracy: 0.6355   \n",
      "Epoch 3/1000\n",
      "2560/2560 [==============================] - 437s - loss: 57.9708 - acc: 0.6152 - categorical_accuracy: 0.6152   \n",
      "Epoch 4/1000\n",
      "2560/2560 [==============================] - 447s - loss: 57.6738 - acc: 0.6125 - categorical_accuracy: 0.6125   \n",
      "Epoch 5/1000\n",
      "2112/2560 [=======================>......] - ETA: 91s - loss: 57.4983 - acc: 0.6264 - categorical_accuracy: 0.6264"
     ]
    }
   ],
   "source": [
    "model.fit(nparray,df.values[:,1:],epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:18:47.915845Z",
     "start_time": "2018-05-02T12:00:30.068364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2560/2560 [==============================] - 546s - loss: 57.8818 - acc: 0.2672   \n",
      "Epoch 2/1000\n",
      "2560/2560 [==============================] - 538s - loss: 57.6013 - acc: 0.6074   \n",
      "Epoch 3/1000\n",
      "2560/2560 [==============================] - 455s - loss: 57.3081 - acc: 0.6191   \n",
      "Epoch 4/1000\n",
      "2560/2560 [==============================] - 468s - loss: 57.0314 - acc: 0.6145   \n",
      "Epoch 5/1000\n",
      "2560/2560 [==============================] - 469s - loss: 56.7828 - acc: 0.6063   \n",
      "Epoch 6/1000\n",
      "2560/2560 [==============================] - 451s - loss: 56.5042 - acc: 0.2422   \n",
      "Epoch 7/1000\n",
      "2560/2560 [==============================] - 439s - loss: 56.2777 - acc: 0.3426   \n",
      "Epoch 8/1000\n",
      "2560/2560 [==============================] - 452s - loss: 56.0032 - acc: 0.6113   \n",
      "Epoch 9/1000\n",
      "2560/2560 [==============================] - 436s - loss: 55.7958 - acc: 0.5941   \n",
      "Epoch 10/1000\n",
      "2560/2560 [==============================] - 437s - loss: 55.5250 - acc: 0.6258   \n",
      "Epoch 11/1000\n",
      "2560/2560 [==============================] - 445s - loss: 55.3094 - acc: 0.6086   \n",
      "Epoch 12/1000\n",
      "2560/2560 [==============================] - 452s - loss: 55.0969 - acc: 0.6203   \n",
      "Epoch 13/1000\n",
      "2560/2560 [==============================] - 437s - loss: 54.8979 - acc: 0.6031   \n",
      "Epoch 14/1000\n",
      "2560/2560 [==============================] - 437s - loss: 54.6304 - acc: 0.6051   \n",
      "Epoch 15/1000\n",
      "2560/2560 [==============================] - 437s - loss: 54.4237 - acc: 0.6004   \n",
      "Epoch 16/1000\n",
      "2560/2560 [==============================] - 437s - loss: 54.2339 - acc: 0.6051   \n",
      "Epoch 17/1000\n",
      "2560/2560 [==============================] - 444s - loss: 54.0678 - acc: 0.5867   \n",
      "Epoch 18/1000\n",
      "2560/2560 [==============================] - 455s - loss: 53.8101 - acc: 0.6230   \n",
      "Epoch 19/1000\n",
      " 256/2560 [==>...........................] - ETA: 409s - loss: 51.2941 - acc: 0.6094"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-5e9dc37e4c78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnparray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(nparray,df.values[:,1:],epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:21:13.689705Z",
     "start_time": "2018-05-02T14:18:53.826553Z"
    }
   },
   "outputs": [],
   "source": [
    "ypred = model.predict(nparray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:21:15.429372Z",
     "start_time": "2018-05-02T14:21:15.376002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.258827 , 6.6775947, 6.8487415, 6.8486757],\n",
       "       [5.258827 , 6.6775947, 6.8487415, 6.8486757],\n",
       "       [5.258827 , 6.6775947, 6.8487415, 6.8486757],\n",
       "       ...,\n",
       "       [5.258827 , 6.6775947, 6.8487415, 6.8486757],\n",
       "       [5.258827 , 6.6775947, 6.8487415, 6.8486757],\n",
       "       [5.258827 , 6.6775947, 6.8487415, 6.8486757]], dtype=float32)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:21:54.188236Z",
     "start_time": "2018-05-02T14:21:54.180495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.8487415, 5.258827)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(ypred[:,:]) , np.min(ypred[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T03:44:36.741718Z",
     "start_time": "2018-04-20T03:44:36.561732Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86784\n",
      "12032\n",
      "31744\n",
      "6144\n",
      "99584\n",
      "82944\n",
      "105728\n",
      "189952\n",
      "177408\n",
      "76288\n",
      "42240\n",
      "29440\n",
      "208640\n",
      "66048\n",
      "50944\n",
      "177664\n",
      "206080\n",
      "71168\n",
      "40192\n",
      "38400\n",
      "214016\n",
      "5632\n",
      "85248\n",
      "67840\n",
      "123904\n",
      "210432\n",
      "83712\n",
      "182784\n",
      "142336\n",
      "147456\n",
      "39680\n",
      "113920\n",
      "111872\n",
      "128512\n",
      "98560\n",
      "114176\n",
      "216320\n",
      "179712\n",
      "124672\n",
      "45056\n",
      "52224\n",
      "108032\n",
      "44288\n",
      "1536\n",
      "185088\n",
      "143616\n",
      "200960\n",
      "163072\n",
      "186624\n",
      "26112\n",
      "80896\n",
      "82688\n",
      "139264\n",
      "43776\n",
      "101376\n",
      "23040\n",
      "170240\n",
      "86272\n",
      "27904\n",
      "43008\n",
      "96000\n",
      "213760\n",
      "19968\n",
      "164864\n",
      "28928\n",
      "187392\n",
      "14080\n",
      "46848\n",
      "208896\n",
      "166144\n",
      "24320\n",
      "119040\n",
      "113664\n",
      "125952\n",
      "60928\n",
      "52480\n",
      "14592\n",
      "70656\n",
      "214272\n",
      "156416\n",
      "29696\n",
      "48128\n",
      "96768\n",
      "60416\n",
      "97024\n",
      "9728\n",
      "42496\n",
      "146944\n",
      "72704\n",
      "196608\n",
      "66816\n",
      "18944\n",
      "68608\n",
      "57600\n",
      "90624\n",
      "127744\n",
      "214784\n",
      "2560\n",
      "160256\n",
      "172288\n",
      "35072\n",
      "203264\n",
      "94976\n",
      "130048\n",
      "16640\n",
      "198144\n",
      "103936\n",
      "107776\n",
      "66304\n",
      "63744\n",
      "55808\n",
      "131072\n",
      "186880\n",
      "174592\n",
      "101888\n",
      "216064\n",
      "155392\n",
      "188928\n",
      "82176\n",
      "35328\n",
      "80384\n",
      "84992\n",
      "140032\n",
      "202240\n",
      "123648\n",
      "192256\n",
      "80128\n",
      "137216\n",
      "128256\n",
      "117760\n",
      "27648\n",
      "137984\n",
      "45312\n",
      "40960\n",
      "61952\n",
      "142080\n",
      "139520\n",
      "171264\n",
      "87552\n",
      "211712\n",
      "59904\n",
      "171776\n",
      "129280\n",
      "24064\n",
      "206592\n",
      "139776\n",
      "196352\n",
      "38656\n",
      "123392\n",
      "26368\n",
      "44544\n",
      "73984\n",
      "186112\n",
      "42752\n",
      "1792\n",
      "84480\n",
      "186368\n",
      "165888\n",
      "197120\n",
      "116736\n",
      "176128\n",
      "146176\n",
      "205056\n",
      "136960\n",
      "62720\n",
      "1280\n",
      "10496\n",
      "108544\n",
      "167424\n",
      "77824\n",
      "114944\n",
      "98048\n",
      "52736\n",
      "125440\n",
      "33792\n",
      "144640\n",
      "32256\n",
      "163840\n",
      "22528\n",
      "91136\n",
      "173056\n",
      "134656\n",
      "88064\n",
      "55296\n",
      "72448\n",
      "150272\n",
      "61440\n",
      "200192\n",
      "128768\n",
      "105216\n",
      "201984\n",
      "34048\n",
      "139008\n",
      "136192\n",
      "47616\n",
      "27136\n",
      "214528\n",
      "205568\n",
      "209152\n",
      "18688\n",
      "158208\n",
      "189440\n",
      "18176\n",
      "109312\n",
      "32768\n",
      "51200\n",
      "56320\n",
      "22784\n",
      "199168\n",
      "171008\n",
      "84224\n",
      "58624\n",
      "188160\n",
      "56576\n",
      "123136\n",
      "153856\n",
      "170752\n",
      "145408\n",
      "211968\n",
      "106496\n",
      "130560\n",
      "109824\n",
      "40704\n",
      "215040\n",
      "179200\n",
      "207360\n",
      "29184\n",
      "20224\n",
      "49152\n",
      "98816\n",
      "165120\n",
      "61696\n",
      "159488\n",
      "68864\n",
      "37632\n",
      "159744\n",
      "195840\n",
      "158720\n",
      "18432\n",
      "165632\n",
      "50432\n",
      "93440\n",
      "144896\n",
      "64512\n",
      "215552\n",
      "75520\n",
      "180480\n",
      "137472\n",
      "209408\n",
      "43264\n",
      "126464\n",
      "135680\n",
      "85760\n",
      "165376\n",
      "36608\n",
      "111360\n",
      "96512\n",
      "48640\n",
      "74496\n",
      "91904\n",
      "51712\n",
      "90112\n",
      "79616\n",
      "211200\n",
      "143360\n",
      "120832\n",
      "161280\n",
      "65536\n",
      "2048\n",
      "103168\n",
      "94720\n",
      "71680\n",
      "88832\n",
      "74752\n",
      "121856\n",
      "70144\n",
      "58112\n",
      "35840\n",
      "118272\n",
      "97536\n",
      "161792\n",
      "176896\n",
      "30208\n",
      "44800\n",
      "173824\n",
      "44032\n",
      "184320\n",
      "105984\n",
      "16128\n",
      "149248\n",
      "140288\n",
      "196864\n",
      "86016\n",
      "20480\n",
      "152064\n",
      "75008\n",
      "46336\n",
      "59648\n",
      "7424\n",
      "191488\n",
      "104960\n",
      "120064\n",
      "216576\n",
      "119552\n",
      "108800\n",
      "80640\n",
      "28672\n",
      "192768\n",
      "99840\n",
      "117504\n",
      "64000\n",
      "178944\n",
      "121344\n",
      "70400\n",
      "33536\n",
      "118016\n",
      "144384\n",
      "168448\n",
      "194560\n",
      "8448\n",
      "59392\n",
      "181248\n",
      "200704\n",
      "111616\n",
      "114432\n",
      "217088\n",
      "194048\n",
      "181760\n",
      "5376\n",
      "4352\n",
      "99072\n",
      "190208\n",
      "118784\n",
      "201728\n",
      "169472\n",
      "53760\n",
      "167168\n",
      "46592\n",
      "15104\n",
      "41216\n",
      "95744\n",
      "177920\n",
      "122880\n",
      "68352\n",
      "35584\n",
      "94464\n",
      "127488\n",
      "21504\n",
      "141824\n",
      "141568\n",
      "75264\n",
      "204544\n",
      "133888\n",
      "102912\n",
      "172032\n",
      "114688\n",
      "142592\n",
      "72960\n",
      "66560\n",
      "83200\n",
      "36352\n",
      "33024\n",
      "145664\n",
      "168704\n",
      "148480\n",
      "150784\n",
      "7168\n",
      "70912\n",
      "193536\n",
      "54784\n",
      "164096\n",
      "201472\n",
      "207616\n",
      "60672\n",
      "152576\n",
      "2304\n",
      "115456\n",
      "204800\n",
      "210176\n",
      "8960\n",
      "184576\n",
      "138496\n",
      "124928\n",
      "16384\n",
      "205824\n",
      "207104\n",
      "41984\n",
      "213248\n",
      "34816\n",
      "69120\n",
      "89088\n",
      "33280\n",
      "92928\n",
      "49920\n",
      "212480\n",
      "11776\n",
      "31488\n",
      "174080\n",
      "115712\n",
      "10240\n",
      "10752\n",
      "104448\n",
      "207872\n",
      "211456\n",
      "107520\n",
      "111104\n",
      "93952\n",
      "161536\n",
      "160768\n",
      "64256\n",
      "212224\n",
      "162816\n",
      "157184\n",
      "185344\n",
      "194816\n",
      "91648\n",
      "5120\n",
      "204032\n",
      "119296\n",
      "190976\n",
      "206848\n",
      "60160\n",
      "116480\n",
      "51968\n",
      "166912\n",
      "151040\n",
      "132352\n",
      "25344\n",
      "20736\n",
      "134400\n",
      "120576\n",
      "151808\n",
      "131328\n",
      "178688\n",
      "188672\n",
      "13824\n",
      "107008\n",
      "26880\n",
      "203520\n",
      "21248\n",
      "137728\n",
      "124416\n",
      "90368\n",
      "94208\n",
      "87296\n",
      "105472\n",
      "21760\n",
      "3072\n",
      "215808\n",
      "41728\n",
      "134912\n",
      "216832\n",
      "200448\n",
      "167680\n",
      "107264\n",
      "182272\n",
      "98304\n",
      "218112\n",
      "30464\n",
      "185856\n",
      "175104\n",
      "119808\n",
      "38912\n",
      "77568\n",
      "196096\n",
      "47360\n",
      "162304\n",
      "63488\n",
      "12544\n",
      "122624\n",
      "56832\n",
      "102400\n",
      "4608\n",
      "72192\n",
      "154880\n",
      "63232\n",
      "198912\n",
      "179456\n",
      "79104\n",
      "19712\n",
      "160512\n",
      "218624\n",
      "140544\n",
      "132608\n",
      "27392\n",
      "124160\n",
      "81152\n",
      "176384\n",
      "65792\n",
      "144128\n",
      "45568\n",
      "28160\n",
      "136704\n",
      "6400\n",
      "46080\n",
      "171520\n",
      "195328\n",
      "43520\n",
      "91392\n",
      "178176\n",
      "30720\n",
      "28416\n",
      "103424\n",
      "217344\n",
      "213504\n",
      "103680\n",
      "183808\n",
      "155904\n",
      "115200\n",
      "55040\n",
      "142848\n",
      "77056\n",
      "127232\n",
      "175616\n",
      "62976\n",
      "41472\n",
      "73216\n",
      "143104\n",
      "113408\n",
      "140800\n",
      "151552\n",
      "83456\n",
      "126976\n",
      "34560\n",
      "157696\n",
      "54272\n",
      "17920\n",
      "69376\n",
      "99328\n",
      "37120\n",
      "3328\n",
      "147200\n",
      "54528\n",
      "135168\n",
      "58880\n",
      "78080\n",
      "131840\n",
      "5888\n",
      "167936\n",
      "101632\n",
      "112896\n",
      "203776\n",
      "89600\n",
      "81920\n",
      "93696\n",
      "59136\n",
      "121600\n",
      "130304\n",
      "8192\n",
      "9984\n",
      "109568\n",
      "183296\n",
      "58368\n",
      "136448\n",
      "87808\n",
      "8704\n",
      "180736\n",
      "81664\n",
      "205312\n",
      "37888\n",
      "25088\n",
      "57856\n",
      "172800\n",
      "180224\n",
      "39936\n",
      "64768\n",
      "156160\n",
      "87040\n",
      "4096\n",
      "17664\n",
      "157440\n",
      "101120\n",
      "79360\n",
      "185600\n",
      "12800\n",
      "175872\n",
      "133376\n",
      "174336\n",
      "256\n",
      "100608\n",
      "3584\n",
      "168960\n",
      "160000\n",
      "95488\n",
      "4864\n",
      "106240\n",
      "69632\n",
      "25856\n",
      "146432\n",
      "187904\n",
      "202752\n",
      "175360\n",
      "156672\n",
      "14848\n",
      "177152\n",
      "19200\n",
      "6912\n",
      "9472\n",
      "92672\n",
      "193024\n",
      "163328\n",
      "169984\n",
      "191744\n",
      "73728\n",
      "190464\n",
      "147968\n",
      "195584\n",
      "71424\n",
      "209664\n",
      "155136\n",
      "36864\n",
      "57088\n",
      "24576\n",
      "126208\n",
      "62208\n",
      "198400\n",
      "210688\n",
      "17408\n",
      "13312\n",
      "85504\n",
      "166656\n",
      "149760\n",
      "112128\n",
      "152832\n",
      "110080\n",
      "182016\n",
      "73472\n",
      "188416\n",
      "47872\n",
      "118528\n",
      "45824\n",
      "159232\n",
      "146688\n",
      "512\n",
      "166400\n",
      "22272\n",
      "187648\n",
      "768\n",
      "161024\n",
      "75776\n",
      "129792\n",
      "106752\n",
      "95232\n",
      "208128\n",
      "134144\n",
      "126720\n",
      "215296\n",
      "51456\n",
      "39168\n",
      "39424\n",
      "153088\n",
      "92160\n",
      "122112\n",
      "112384\n",
      "110592\n",
      "100864\n",
      "157952\n",
      "148736\n",
      "152320\n",
      "145152\n",
      "141312\n",
      "102656\n",
      "113152\n",
      "191232\n",
      "88320\n",
      "129536\n",
      "197888\n",
      "154368\n",
      "153600\n",
      "135936\n",
      "199680\n",
      "31232\n",
      "48384\n",
      "184064\n",
      "34304\n",
      "164608\n",
      "9216\n",
      "62464\n",
      "50688\n",
      "164352\n",
      "130816\n",
      "15616\n",
      "2816\n",
      "155648\n",
      "12288\n",
      "32512\n",
      "52992\n",
      "40448\n",
      "203008\n",
      "102144\n",
      "57344\n",
      "202496\n",
      "15360\n",
      "187136\n",
      "53248\n",
      "36096\n",
      "121088\n",
      "77312\n",
      "141056\n",
      "110336\n",
      "92416\n",
      "158464\n",
      "218368\n",
      "195072\n",
      "110848\n",
      "1024\n",
      "147712\n",
      "117248\n",
      "13568\n",
      "129024\n",
      "193280\n",
      "90880\n",
      "162560\n",
      "135424\n",
      "189184\n",
      "217600\n",
      "112640\n",
      "89344\n",
      "116992\n",
      "209920\n",
      "183552\n",
      "88576\n",
      "199936\n",
      "47104\n",
      "78848\n",
      "11520\n",
      "49408\n",
      "68096\n",
      "138752\n",
      "138240\n",
      "170496\n",
      "169216\n",
      "23552\n",
      "78336\n",
      "30976\n",
      "122368\n",
      "132096\n",
      "38144\n",
      "150528\n",
      "109056\n",
      "83968\n",
      "125184\n",
      "56064\n",
      "7680\n",
      "197376\n",
      "20992\n",
      "67328\n",
      "69888\n",
      "180992\n",
      "148224\n",
      "133120\n",
      "131584\n",
      "173568\n",
      "100352\n",
      "194304\n",
      "115968\n",
      "37376\n",
      "74240\n",
      "48896\n",
      "150016\n",
      "22016\n",
      "151296\n",
      "104192\n",
      "79872\n",
      "181504\n",
      "76032\n",
      "61184\n",
      "212736\n",
      "210944\n",
      "108288\n",
      "143872\n",
      "54016\n",
      "192000\n",
      "168192\n",
      "93184\n",
      "19456\n",
      "23296\n",
      "172544\n",
      "158976\n",
      "81408\n",
      "133632\n",
      "13056\n",
      "14336\n",
      "184832\n",
      "212992\n",
      "6656\n",
      "11264\n",
      "16896\n",
      "23808\n",
      "97792\n",
      "128000\n",
      "208384\n",
      "154624\n",
      "179968\n",
      "154112\n",
      "49664\n",
      "153344\n",
      "11008\n",
      "156928\n",
      "17152\n",
      "97280\n",
      "25600\n",
      "32000\n",
      "116224\n",
      "173312\n",
      "104704\n",
      "3840\n",
      "89856\n",
      "76544\n",
      "55552\n",
      "198656\n",
      "86528\n",
      "65280\n",
      "53504\n",
      "132864\n",
      "178432\n",
      "192512\n",
      "29952\n",
      "125696\n",
      "148992\n",
      "199424\n",
      "50176\n",
      "71936\n",
      "190720\n",
      "169728\n",
      "162048\n",
      "174848\n",
      "183040\n",
      "7936\n",
      "206336\n",
      "82432\n",
      "149504\n",
      "197632\n",
      "67072\n",
      "163584\n",
      "76800\n",
      "78592\n",
      "217856\n",
      "204288\n",
      "120320\n",
      "96256\n",
      "193792\n",
      "100096\n",
      "67584\n",
      "26624\n",
      "189696\n",
      "176640\n",
      "201216\n",
      "84736\n",
      "65024\n",
      "15872\n",
      "24832\n",
      "182528\n",
      "145920\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(\"Data/patchTrain/\")[:1000]:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:45:24.684242Z",
     "start_time": "2018-04-24T14:44:10.873821Z"
    }
   },
   "outputs": [],
   "source": [
    "nparray = np.zeros(shape=(256*10,33,32,32),dtype=np.float32)\n",
    "indices = []\n",
    "counter=0\n",
    "for j in os.listdir(\"Data/patchTrain/\")[:10]:\n",
    "    for i in os.listdir(\"Data/patchTrain/\"+str(j)+\"/\"):\n",
    "        nparray[counter] = crop_center(tiff.imread(\"Data/patchTrain/\"+j+\"/\"+i),32,32)/255.0\n",
    "        indices += [int(i.split(\"_\")[1].split(\".\")[0])]\n",
    "        counter+=1\n",
    "\n",
    "df = pd.read_csv(\"Data/occurrences_train.csv\",sep=';', error_bad_lines=False)\n",
    "df = df[[\"class\",\"order\"]]\n",
    "df = df.iloc[indices,:]\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "encoder = LabelEncoder()\n",
    "encoder = encoder.fit(df['class'])\n",
    "df ['class'] = encoder.transform(df['class'])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder = encoder.fit(df['order'])\n",
    "df ['order'] = encoder.transform(df['order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T14:45:55.841725Z",
     "start_time": "2018-04-24T14:45:47.093618Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (36,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/occurrences_train.csv\",sep=';', error_bad_lines=False)\n",
    "df = df[[\"class\",\"order\"]]\n",
    "df = df.iloc[indices,:]\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "encoder = LabelEncoder()\n",
    "encoder = encoder.fit(df['class'])\n",
    "df ['class'] = encoder.transform(df['class'])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder = encoder.fit(df['order'])\n",
    "df ['order'] = encoder.transform(df['order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T03:45:50.519403Z",
     "start_time": "2018-04-20T03:45:50.366454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.5019608 , 0.5019608 , 0.5058824 , ..., 0.50980395,\n",
       "          0.5058824 , 0.50980395],\n",
       "         [0.5019608 , 0.5019608 , 0.5058824 , ..., 0.50980395,\n",
       "          0.50980395, 0.5058824 ],\n",
       "         [0.5019608 , 0.5019608 , 0.5019608 , ..., 0.5058824 ,\n",
       "          0.5058824 , 0.50980395],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.5137255 , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.5137255 , 0.50980395, ..., 0.        ,\n",
       "          0.5176471 , 0.5176471 ],\n",
       "         [0.        , 0.5137255 , 0.50980395, ..., 0.5137255 ,\n",
       "          0.5137255 , 0.5137255 ]],\n",
       "\n",
       "        [[0.7176471 , 0.7176471 , 0.7176471 , ..., 0.7176471 ,\n",
       "          0.7176471 , 0.7176471 ],\n",
       "         [0.7176471 , 0.7176471 , 0.7176471 , ..., 0.7176471 ,\n",
       "          0.7176471 , 0.7176471 ],\n",
       "         [0.7137255 , 0.7137255 , 0.7176471 , ..., 0.7176471 ,\n",
       "          0.7176471 , 0.7176471 ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.73333335, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.73333335, 0.73333335, 0.7294118 , ..., 0.73333335,\n",
       "          0.73333335, 0.7294118 ],\n",
       "         [0.        , 0.73333335, 0.7294118 , ..., 0.7254902 ,\n",
       "          0.7254902 , 0.72156864]],\n",
       "\n",
       "        [[0.20784314, 0.20784314, 0.20784314, ..., 0.23921569,\n",
       "          0.24313726, 0.24313726],\n",
       "         [0.20784314, 0.21176471, 0.21176471, ..., 0.24313726,\n",
       "          0.24313726, 0.24313726],\n",
       "         [0.21176471, 0.21176471, 0.21176471, ..., 0.24313726,\n",
       "          0.24313726, 0.24705882],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.24705882, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.24705882, 0.24705882, 0.24705882, ..., 0.28627452,\n",
       "          0.2901961 , 0.2901961 ],\n",
       "         [0.        , 0.24705882, 0.2509804 , ..., 0.2901961 ,\n",
       "          0.2901961 , 0.2901961 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314, ..., 0.01176471,\n",
       "          0.01176471, 0.01176471],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.01176471,\n",
       "          0.01176471, 0.01176471],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.01176471,\n",
       "          0.01176471, 0.00784314],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.01176471],\n",
       "         [0.        , 0.        , 0.        , ..., 0.01176471,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         ...,\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314]]],\n",
       "\n",
       "\n",
       "       [[[0.6039216 , 0.6117647 , 0.6156863 , ..., 0.70980394,\n",
       "          0.70980394, 0.70980394],\n",
       "         [0.6039216 , 0.60784316, 0.6117647 , ..., 0.70980394,\n",
       "          0.70980394, 0.70980394],\n",
       "         [0.59607846, 0.6039216 , 0.60784316, ..., 0.70980394,\n",
       "          0.70980394, 0.70980394],\n",
       "         ...,\n",
       "         [0.5921569 , 0.5921569 , 0.6       , ..., 0.7019608 ,\n",
       "          0.7058824 , 0.7058824 ],\n",
       "         [0.59607846, 0.6039216 , 0.6039216 , ..., 0.69803923,\n",
       "          0.69803923, 0.7019608 ],\n",
       "         [0.59607846, 0.6       , 0.6       , ..., 0.69803923,\n",
       "          0.69803923, 0.70980394]],\n",
       "\n",
       "        [[0.61960787, 0.627451  , 0.6313726 , ..., 0.7294118 ,\n",
       "          0.7294118 , 0.7294118 ],\n",
       "         [0.6156863 , 0.61960787, 0.627451  , ..., 0.7294118 ,\n",
       "          0.7294118 , 0.7294118 ],\n",
       "         [0.60784316, 0.6117647 , 0.61960787, ..., 0.7294118 ,\n",
       "          0.7294118 , 0.7294118 ],\n",
       "         ...,\n",
       "         [0.6039216 , 0.60784316, 0.6156863 , ..., 0.7254902 ,\n",
       "          0.7294118 , 0.7294118 ],\n",
       "         [0.60784316, 0.6156863 , 0.61960787, ..., 0.72156864,\n",
       "          0.72156864, 0.7254902 ],\n",
       "         [0.60784316, 0.6117647 , 0.6156863 , ..., 0.72156864,\n",
       "          0.7254902 , 0.7294118 ]],\n",
       "\n",
       "        [[0.8627451 , 0.8627451 , 0.8627451 , ..., 0.8627451 ,\n",
       "          0.8627451 , 0.85882354],\n",
       "         [0.8627451 , 0.8627451 , 0.8627451 , ..., 0.8627451 ,\n",
       "          0.85882354, 0.85882354],\n",
       "         [0.8627451 , 0.8627451 , 0.8627451 , ..., 0.8627451 ,\n",
       "          0.85882354, 0.85882354],\n",
       "         ...,\n",
       "         [0.85882354, 0.85882354, 0.85882354, ..., 0.85490197,\n",
       "          0.85490197, 0.85490197],\n",
       "         [0.85882354, 0.85882354, 0.85882354, ..., 0.85490197,\n",
       "          0.85490197, 0.85490197],\n",
       "         [0.85882354, 0.85882354, 0.85882354, ..., 0.85490197,\n",
       "          0.85490197, 0.85490197]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314, ..., 0.01568628,\n",
       "          0.01568628, 0.01568628],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.01568628,\n",
       "          0.01568628, 0.01568628],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.01568628,\n",
       "          0.01568628, 0.01568628],\n",
       "         ...,\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.01568628,\n",
       "          0.01568628, 0.01568628],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.01568628,\n",
       "          0.01568628, 0.01568628],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.01568628,\n",
       "          0.01568628, 0.01568628]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.00392157, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.00392157, 0.00392157, 0.00392157, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.00392157, 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         ...,\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314]]],\n",
       "\n",
       "\n",
       "       [[[0.74509805, 0.7411765 , 0.7372549 , ..., 0.7019608 ,\n",
       "          0.7019608 , 0.7019608 ],\n",
       "         [0.7490196 , 0.7490196 , 0.7411765 , ..., 0.69803923,\n",
       "          0.69411767, 0.7019608 ],\n",
       "         [0.7529412 , 0.7490196 , 0.74509805, ..., 0.69411767,\n",
       "          0.69411767, 0.7019608 ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.78431374, 0.78431374, 0.7764706 , ..., 0.7529412 ,\n",
       "          0.7529412 , 0.7529412 ],\n",
       "         [0.7882353 , 0.7882353 , 0.78039217, ..., 0.7490196 ,\n",
       "          0.7490196 , 0.7529412 ],\n",
       "         [0.7921569 , 0.7921569 , 0.7882353 , ..., 0.7490196 ,\n",
       "          0.74509805, 0.7529412 ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.8039216 ,\n",
       "          0.80784315, 0.8117647 ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.8117647 ,\n",
       "          0.8156863 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.54509807, 0.54509807, 0.54509807, ..., 0.5568628 ,\n",
       "          0.5568628 , 0.5568628 ],\n",
       "         [0.5411765 , 0.5411765 , 0.54509807, ..., 0.5529412 ,\n",
       "          0.5529412 , 0.5529412 ],\n",
       "         [0.5372549 , 0.5411765 , 0.5411765 , ..., 0.54901963,\n",
       "          0.54901963, 0.5529412 ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.4627451 ,\n",
       "          0.4627451 , 0.4627451 ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.45882353,\n",
       "          0.45882353, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.        , 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.        , 0.        , 0.        , ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.        , 0.        , 0.        , ..., 0.00784314,\n",
       "          0.00784314, 0.00784314]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         ...,\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00392157, 0.00392157, 0.00392157, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00392157, 0.00392157, 0.00392157, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.6156863 , 0.6156863 , 0.6156863 , ..., 0.6117647 ,\n",
       "          0.6117647 , 0.6156863 ],\n",
       "         [0.6156863 , 0.6156863 , 0.6156863 , ..., 0.6156863 ,\n",
       "          0.61960787, 0.61960787],\n",
       "         [0.6156863 , 0.6156863 , 0.6156863 , ..., 0.61960787,\n",
       "          0.61960787, 0.62352943],\n",
       "         ...,\n",
       "         [0.59607846, 0.59607846, 0.59607846, ..., 0.6       ,\n",
       "          0.6       , 0.6       ],\n",
       "         [0.6       , 0.6       , 0.6       , ..., 0.60784316,\n",
       "          0.60784316, 0.60784316],\n",
       "         [0.6       , 0.6       , 0.6       , ..., 0.6       ,\n",
       "          0.6039216 , 0.60784316]],\n",
       "\n",
       "        [[0.7019608 , 0.7019608 , 0.7058824 , ..., 0.6862745 ,\n",
       "          0.6901961 , 0.69803923],\n",
       "         [0.70980394, 0.70980394, 0.70980394, ..., 0.69411767,\n",
       "          0.69803923, 0.7019608 ],\n",
       "         [0.70980394, 0.7137255 , 0.7137255 , ..., 0.7019608 ,\n",
       "          0.7058824 , 0.70980394],\n",
       "         ...,\n",
       "         [0.6745098 , 0.6745098 , 0.6784314 , ..., 0.68235296,\n",
       "          0.68235296, 0.68235296],\n",
       "         [0.6745098 , 0.6745098 , 0.6745098 , ..., 0.68235296,\n",
       "          0.68235296, 0.68235296],\n",
       "         [0.6784314 , 0.6784314 , 0.6745098 , ..., 0.6862745 ,\n",
       "          0.6862745 , 0.6862745 ]],\n",
       "\n",
       "        [[0.74509805, 0.74509805, 0.74509805, ..., 0.7529412 ,\n",
       "          0.7529412 , 0.7529412 ],\n",
       "         [0.74509805, 0.7490196 , 0.7490196 , ..., 0.7529412 ,\n",
       "          0.7529412 , 0.7529412 ],\n",
       "         [0.7490196 , 0.7490196 , 0.7490196 , ..., 0.7529412 ,\n",
       "          0.7529412 , 0.7529412 ],\n",
       "         ...,\n",
       "         [0.7647059 , 0.7647059 , 0.7647059 , ..., 0.7647059 ,\n",
       "          0.7647059 , 0.7647059 ],\n",
       "         [0.7647059 , 0.7647059 , 0.7647059 , ..., 0.76862746,\n",
       "          0.76862746, 0.76862746],\n",
       "         [0.7647059 , 0.7647059 , 0.7647059 , ..., 0.76862746,\n",
       "          0.76862746, 0.76862746]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.00784314, 0.00784314, 0.01176471, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.00392157, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00392157, 0.00392157, 0.00392157, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00392157, 0.00392157, 0.00392157, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.00392157, 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.11372549, 0.11372549, 0.11372549, ..., 0.09019608,\n",
       "          0.09019608, 0.09019608],\n",
       "         [0.11372549, 0.11372549, 0.11372549, ..., 0.09019608,\n",
       "          0.09019608, 0.09019608],\n",
       "         [0.11372549, 0.11372549, 0.11372549, ..., 0.09019608,\n",
       "          0.09019608, 0.09019608],\n",
       "         ...,\n",
       "         [0.04705882, 0.04705882, 0.04705882, ..., 0.04705882,\n",
       "          0.00784314, 0.04705882],\n",
       "         [0.04705882, 0.04705882, 0.04705882, ..., 0.04705882,\n",
       "          0.04705882, 0.04705882],\n",
       "         [0.04705882, 0.04705882, 0.04705882, ..., 0.07843138,\n",
       "          0.07843138, 0.04705882]]],\n",
       "\n",
       "\n",
       "       [[[0.7176471 , 0.7058824 , 0.7254902 , ..., 0.6901961 ,\n",
       "          0.7176471 , 0.7372549 ],\n",
       "         [0.7372549 , 0.7176471 , 0.7294118 , ..., 0.70980394,\n",
       "          0.70980394, 0.7176471 ],\n",
       "         [0.73333335, 0.7372549 , 0.7372549 , ..., 0.7372549 ,\n",
       "          0.7372549 , 0.7294118 ],\n",
       "         ...,\n",
       "         [0.7490196 , 0.7490196 , 0.7490196 , ..., 0.77254903,\n",
       "          0.76862746, 0.77254903],\n",
       "         [0.7607843 , 0.7607843 , 0.75686276, ..., 0.77254903,\n",
       "          0.76862746, 0.77254903],\n",
       "         [0.7647059 , 0.7647059 , 0.7647059 , ..., 0.77254903,\n",
       "          0.76862746, 0.76862746]],\n",
       "\n",
       "        [[0.73333335, 0.7294118 , 0.7372549 , ..., 0.72156864,\n",
       "          0.7372549 , 0.75686276],\n",
       "         [0.7529412 , 0.74509805, 0.7490196 , ..., 0.7372549 ,\n",
       "          0.7372549 , 0.74509805],\n",
       "         [0.7490196 , 0.7529412 , 0.75686276, ..., 0.7607843 ,\n",
       "          0.75686276, 0.7529412 ],\n",
       "         ...,\n",
       "         [0.77254903, 0.7764706 , 0.7764706 , ..., 0.8039216 ,\n",
       "          0.8039216 , 0.8039216 ],\n",
       "         [0.7921569 , 0.7882353 , 0.7882353 , ..., 0.8039216 ,\n",
       "          0.8039216 , 0.8039216 ],\n",
       "         [0.79607844, 0.79607844, 0.7921569 , ..., 0.80784315,\n",
       "          0.8039216 , 0.8       ]],\n",
       "\n",
       "        [[0.69803923, 0.69803923, 0.69803923, ..., 0.6862745 ,\n",
       "          0.68235296, 0.68235296],\n",
       "         [0.69803923, 0.69803923, 0.69411767, ..., 0.68235296,\n",
       "          0.68235296, 0.68235296],\n",
       "         [0.69411767, 0.69411767, 0.69411767, ..., 0.6784314 ,\n",
       "          0.6784314 , 0.6784314 ],\n",
       "         ...,\n",
       "         [0.6313726 , 0.6313726 , 0.6313726 , ..., 0.6117647 ,\n",
       "          0.6117647 , 0.60784316],\n",
       "         [0.6313726 , 0.627451  , 0.627451  , ..., 0.60784316,\n",
       "          0.60784316, 0.60784316],\n",
       "         [0.627451  , 0.627451  , 0.62352943, ..., 0.6039216 ,\n",
       "          0.6039216 , 0.6039216 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         ...,\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.09019608, 0.09019608, 0.09019608, ..., 0.09019608,\n",
       "          0.09803922, 0.09803922],\n",
       "         [0.09019608, 0.09019608, 0.09019608, ..., 0.09019608,\n",
       "          0.09019608, 0.09803922],\n",
       "         [0.09019608, 0.09019608, 0.09019608, ..., 0.09019608,\n",
       "          0.09019608, 0.09803922],\n",
       "         ...,\n",
       "         [0.09803922, 0.09803922, 0.09803922, ..., 0.09019608,\n",
       "          0.09019608, 0.09019608],\n",
       "         [0.09803922, 0.08235294, 0.08235294, ..., 0.09019608,\n",
       "          0.09019608, 0.09019608],\n",
       "         [0.09803922, 0.09803922, 0.08235294, ..., 0.09019608,\n",
       "          0.09019608, 0.09019608]]],\n",
       "\n",
       "\n",
       "       [[[0.7607843 , 0.7607843 , 0.7607843 , ..., 0.75686276,\n",
       "          0.7529412 , 0.76862746],\n",
       "         [0.75686276, 0.7529412 , 0.7490196 , ..., 0.76862746,\n",
       "          0.7647059 , 0.76862746],\n",
       "         [0.74509805, 0.74509805, 0.74509805, ..., 0.7647059 ,\n",
       "          0.76862746, 0.76862746],\n",
       "         ...,\n",
       "         [0.77254903, 0.77254903, 0.77254903, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.76862746, 0.77254903, 0.77254903, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.76862746, 0.76862746, 0.76862746, ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.7921569 , 0.7921569 , 0.7921569 , ..., 0.79607844,\n",
       "          0.79607844, 0.8039216 ],\n",
       "         [0.78431374, 0.78431374, 0.78431374, ..., 0.8039216 ,\n",
       "          0.80784315, 0.80784315],\n",
       "         [0.7764706 , 0.7764706 , 0.7764706 , ..., 0.80784315,\n",
       "          0.80784315, 0.8117647 ],\n",
       "         ...,\n",
       "         [0.8156863 , 0.8156863 , 0.8156863 , ..., 0.8235294 ,\n",
       "          0.8235294 , 0.8235294 ],\n",
       "         [0.8156863 , 0.8156863 , 0.8156863 , ..., 0.8235294 ,\n",
       "          0.        , 0.        ],\n",
       "         [0.8156863 , 0.8156863 , 0.8156863 , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.5803922 , 0.5803922 , 0.5803922 , ..., 0.5529412 ,\n",
       "          0.5529412 , 0.5529412 ],\n",
       "         [0.5803922 , 0.5764706 , 0.5764706 , ..., 0.5529412 ,\n",
       "          0.54901963, 0.54901963],\n",
       "         [0.5764706 , 0.5764706 , 0.57254905, ..., 0.54901963,\n",
       "          0.54901963, 0.54509807],\n",
       "         ...,\n",
       "         [0.50980395, 0.50980395, 0.5058824 , ..., 0.4745098 ,\n",
       "          0.4745098 , 0.4745098 ],\n",
       "         [0.5058824 , 0.5058824 , 0.5058824 , ..., 0.4745098 ,\n",
       "          0.        , 0.        ],\n",
       "         [0.5058824 , 0.5019608 , 0.5019608 , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.00784314,\n",
       "          0.00784314, 0.00784314],\n",
       "         ...,\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.00392157,\n",
       "          0.00392157, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.00392157,\n",
       "          0.00392157, 0.00392157],\n",
       "         [0.        , 0.        , 0.        , ..., 0.00392157,\n",
       "          0.00392157, 0.00392157]],\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314, ..., 0.09411765,\n",
       "          0.09411765, 0.09411765],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.09411765,\n",
       "          0.09411765, 0.09411765],\n",
       "         [0.00784314, 0.00784314, 0.00784314, ..., 0.09411765,\n",
       "          0.09411765, 0.09411765],\n",
       "         ...,\n",
       "         [0.01176471, 0.01176471, 0.07843138, ..., 0.03921569,\n",
       "          0.03921569, 0.07843138],\n",
       "         [0.01176471, 0.01176471, 0.07843138, ..., 0.03921569,\n",
       "          0.03921569, 0.03921569],\n",
       "         [0.01176471, 0.01176471, 0.00784314, ..., 0.03921569,\n",
       "          0.03921569, 0.03921569]]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nparray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T03:58:29.748291Z",
     "start_time": "2018-04-20T03:58:29.741821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5120, 33, 32, 32) (5120, 2)\n"
     ]
    }
   ],
   "source": [
    "print nparray.shape , df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T04:29:59.348341Z",
     "start_time": "2018-04-20T04:29:59.295561Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_23 to have shape (None, 1) but got array with shape (5120, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-a58ace0799eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnparray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1383\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1384\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    142\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_23 to have shape (None, 1) but got array with shape (5120, 2)"
     ]
    }
   ],
   "source": [
    "model.fit(nparray,df.values,epochs=1,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T03:52:46.093708Z",
     "start_time": "2018-04-20T03:52:46.069680Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 24],\n",
       "       [ 3, 24],\n",
       "       [ 3, 11],\n",
       "       ...,\n",
       "       [ 3,  3],\n",
       "       [ 3,  3],\n",
       "       [ 3,  3]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T04:17:38.278761Z",
     "start_time": "2018-04-20T04:15:20.375823Z"
    }
   },
   "outputs": [],
   "source": [
    "ypred = model.predict(nparray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T04:19:33.579496Z",
     "start_time": "2018-04-20T04:19:33.573194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(df.values[:,0]) , np.min(df.values[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T04:19:18.126601Z",
     "start_time": "2018-04-20T04:19:18.120175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8106967, 0.33322722)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(ypred[:,0]) , np.min(ypred[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T04:18:44.184140Z",
     "start_time": "2018-04-20T04:18:44.176110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58821476, 3.3585274 ],\n",
       "       [0.56894076, 3.3399484 ],\n",
       "       [0.6069794 , 3.3722222 ],\n",
       "       ...,\n",
       "       [0.5786255 , 3.330465  ],\n",
       "       [0.63559383, 3.3927653 ],\n",
       "       [0.62512434, 3.3843596 ]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

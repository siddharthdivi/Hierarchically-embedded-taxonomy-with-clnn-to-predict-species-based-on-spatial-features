{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T17:14:49.265030Z",
     "start_time": "2018-05-24T17:14:28.875953Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import tifffile as tif\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "from sklearn.utils import shuffle\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.utils import Sequence\n",
    "from keras.models import load_model, save_model\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Preprocess():\n",
    "    \n",
    "    def init_load(self, root_dir, csv_file):\n",
    "        self.df = pd.read_csv(csv_file, low_memory=False)\n",
    "        self.path = root_dir\n",
    "    \n",
    "    def create_mappings_for_unique_labels(self):\n",
    "        # getting all unique names from csv file\n",
    "        self.classes = list(sorted(self.df['class'].unique()))\n",
    "        self.orders = list(sorted(self.df['order'].unique()))\n",
    "        self.family = list(sorted(self.df['family'].unique()))\n",
    "        self.genus = list(sorted(self.df['genus'].unique()))\n",
    "        self.species = list(sorted(self.df['species_glc_id'].unique()))\n",
    "        self.all_names = self.classes + self.orders + self.family + self.genus + self.species\n",
    "        # creting map for one hot encoding / embedding\n",
    "        self.all_encoded = {}\n",
    "        self.all_rev_encoded = {}\n",
    "        \n",
    "        for i, name in enumerate(self.all_names):\n",
    "            self.all_encoded[str(name)] = i\n",
    "            self.all_rev_encoded[int(i)] = str(name)\n",
    "                \n",
    "    def train_test_data_loading(self):\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = [], [], [], []\n",
    "        for cls in self.df['class'].unique():\n",
    "            #if(cls not in ['Magnoliopsida']):\n",
    "                for order in self.df[self.df['class']==cls]['order'].unique():\n",
    "                    for family in self.df[(self.df['class']==cls) & (self.df['order']==order)]['family'].unique():\n",
    "                        for genus in self.df[(self.df['class']==cls) & (self.df['order']==order) & (self.df['family']==family)]['genus'].unique():\n",
    "                            for species in self.df[(self.df['class']==cls) & (self.df['order']==order) & (self.df['family']==family) & (self.df['genus']==genus)]['species_glc_id'].unique():\n",
    "                                path = self.path+\"train/\"+cls+\"/\"+order+\"/\"+family+\"/\"+genus+\"/\"+str(species)+\"/\"\n",
    "                                self.x_train.extend([path+i for i in os.listdir(path)])\n",
    "                                path = self.path+\"test/\"+cls+\"/\"+order+\"/\"+family+\"/\"+genus+\"/\"+str(species)+\"/\"\n",
    "                                self.x_test.extend([path+i for i in os.listdir(path)])\n",
    "        \n",
    "        np.random.shuffle(self.x_train)\n",
    "        np.random.shuffle(self.x_test)\n",
    "        \n",
    "        for im in self.x_train:\n",
    "            l = im.split(\"/\")\n",
    "            c, o, f, g, s = self.all_encoded[l[3]], self.all_encoded[l[4]], self.all_encoded[l[5]], self.all_encoded[l[6]], self.all_encoded[l[7]]\n",
    "            self.y_train.append([[c],[o],[f],[g],[s]])\n",
    "            \n",
    "        for im in self.x_test:\n",
    "            l = im.split(\"/\")\n",
    "            c, o, f, g, s = self.all_encoded[l[3]], self.all_encoded[l[4]], self.all_encoded[l[5]], self.all_encoded[l[6]], self.all_encoded[l[7]] #self.embed_vectors1['class'][self.all_encoded[l[3]]], self.embed_vectors1['order'][self.all_encoded[l[4]]], self.embed_vectors1['family'][self.all_encoded[l[5]]], self.embed_vectors1['genus'][self.all_encoded[l[6]]], self.embed_vectors2['species_glc_id'][int(l[7])]\n",
    "            self.y_test.append([[c],[o],[f],[g],[s]])\n",
    "        \n",
    "    def ordered_call(self, root_dir, csv_file):\n",
    "        print(\"Creating the data preprocessing object and loading csv\")\n",
    "        self.init_load(root_dir, csv_file)\n",
    "        print(\"Done!\")\n",
    "        print(\"Creating unique mappings for labels\")\n",
    "        self.create_mappings_for_unique_labels()\n",
    "        print(\"Done!\")\n",
    "        print(\"Loading test and train image paths and corresponding labels\")\n",
    "        self.train_test_data_loading()\n",
    "        print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data_Preprocess()\n",
    "data.ordered_call(root_dir=\"Data/Hierarchial Data/\", csv_file=\"occurrences_train.csv\")\n",
    "data.x_train, data.y_train, data.x_test, data.y_test = np.array(data.x_train), np.array(data.y_train), np.array(data.x_test), np.array(data.y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, x_metadata, y_metadata, batch_size, crop_size):\n",
    "        self.x = x_metadata\n",
    "        self.y = y_metadata\n",
    "        self.batch_size = batch_size\n",
    "        self.cp = crop_size\n",
    "        self.dic = {0:3,1:2,2:2,3:1,4:3,5:3,6:1,7:1,8:1,9:1}\n",
    "        self.conv_dic = {0:[133,1176],1:[-10.00984,18.36730],2:[7.846126,20.94560],3:[41.182110,59.95573],4:[302.772980,777.74048],5:[6.182446,36.54550],6:[-28.248663,5.33183],7:[16.744829,41.94211],8:[-14.122952,22.96798],9:[-17.672335,26.44534],10:[-2.738379,26.44534],11:[-17.672335,11.73241],12:[318.297485,2543.30225],13:[43.063732,285.43790],14:[3.022581,135.58406],15:[8.283675,57.78888],16:[121.616867,855.52594],17:[19.868601,421.27750],18:[19.868601,851.60620],19:[60.590000,520.31244],20:[-187.999999,4672.000000]}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        x = []\n",
    "        for i in range(len(batch_x)):\n",
    "            temp = tif.imread(batch_x[i])[:,:,:]\n",
    "            for k in range(21):\n",
    "                temp[k] = self.conv_dic[k][0] + (self.conv_dic[k][1] - self.conv_dic[k][0]) * ((temp[k]/255.0) - 0.1) / 0.8\n",
    "            x.append(np.transpose(temp,(1,2,0)))\n",
    "        return np.array(x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T17:17:40.413914Z",
     "start_time": "2018-05-24T17:17:40.383479Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_build(input_shape,time_steps,num_classes):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T17:17:41.237936Z",
     "start_time": "2018-05-24T17:17:41.112710Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ab707210d54b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-850b42dbd538>\u001b[0m in \u001b[0;36mmodel_build\u001b[0;34m(input_shape, time_steps, num_classes)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inp' is not defined"
     ]
    }
   ],
   "source": [
    "model = model_build((64,64,1),5,4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

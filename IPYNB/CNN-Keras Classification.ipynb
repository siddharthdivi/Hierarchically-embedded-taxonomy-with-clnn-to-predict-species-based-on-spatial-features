{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T17:54:09.749157Z",
     "start_time": "2018-05-26T17:54:08.092115Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import tifffile as tif\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "from sklearn.utils import shuffle\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import load_model, save_model\n",
    "from livelossplot import PlotLossesKeras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.callbacks import EarlyStopping\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms, utils\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T17:54:09.990008Z",
     "start_time": "2018-05-26T17:54:09.751428Z"
    }
   },
   "outputs": [],
   "source": [
    "class Data_Preprocess():\n",
    "    \n",
    "    def init_load(self, root_dir, csv_file):\n",
    "        self.df = pd.read_csv(csv_file, low_memory=False)\n",
    "        self.path = root_dir\n",
    "    \n",
    "    def create_mappings_for_unique_labels(self):\n",
    "        # getting all unique names from csv file\n",
    "        self.classes = list(sorted(self.df['class'].unique()))\n",
    "        self.orders = list(sorted(self.df['order'].unique()))\n",
    "        self.family = list(sorted(self.df['family'].unique()))\n",
    "        self.genus = list(sorted(self.df['genus'].unique()))\n",
    "        self.species = list(sorted(self.df['species_glc_id'].unique()))\n",
    "        self.all_names = self.classes + self.orders + self.family + self.genus + self.species\n",
    "        # creting map for one hot encoding / embedding\n",
    "        self.all_encoded = {}\n",
    "        self.all_rev_encoded = {}\n",
    "        \n",
    "        for i, name in enumerate(self.all_names):\n",
    "            self.all_encoded[str(name)] = i\n",
    "            self.all_rev_encoded[int(i)] = str(name)\n",
    "        \n",
    "        self.embeddings = pkl.load(open(\"Data/final_embeddings.pkl\",\"rb\"), encoding='latin')\n",
    "        \n",
    "        \n",
    "    def train_test_data_loading(self):\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = [], [], [], []\n",
    "        for cls in self.df['class'].unique():\n",
    "                for order in self.df[self.df['class']==cls]['order'].unique():\n",
    "                    for family in self.df[(self.df['class']==cls) & (self.df['order']==order)]['family'].unique():\n",
    "                        for genus in self.df[(self.df['class']==cls) & (self.df['order']==order) & (self.df['family']==family)]['genus'].unique():\n",
    "                            for species in self.df[(self.df['class']==cls) & (self.df['order']==order) & (self.df['family']==family) & (self.df['genus']==genus)]['species_glc_id'].unique():\n",
    "                                path = self.path+\"train/\"+cls+\"/\"+order+\"/\"+family+\"/\"+genus+\"/\"+str(species)+\"/\"\n",
    "                                self.x_train.extend([path+i for i in os.listdir(path)])\n",
    "                                path = self.path+\"test/\"+cls+\"/\"+order+\"/\"+family+\"/\"+genus+\"/\"+str(species)+\"/\"\n",
    "                                self.x_test.extend([path+i for i in os.listdir(path)])\n",
    "        \n",
    "        np.random.shuffle(self.x_train)\n",
    "        np.random.shuffle(self.x_test)\n",
    "        \n",
    "        for im in self.x_train:\n",
    "            l = im.split(\"/\")\n",
    "            c, o, f, g, s = self.all_encoded[l[3]], self.all_encoded[l[4]], self.all_encoded[l[5]], self.all_encoded[l[6]], self.all_encoded[l[7]]\n",
    "            #c, o, f, g, s = self.embeddings[l[3]], self.embeddings[l[4]], self.embeddings[l[5]], self.embeddings[l[6]], self.embeddings[l[7]]\n",
    "            d=np.zeros(56)\n",
    "            d[o]=1\n",
    "            self.y_train.append(d)#,[o],[f],[g],[s]])\n",
    "            \n",
    "        for im in self.x_test:\n",
    "            l = im.split(\"/\")\n",
    "            c, o, f, g, s = self.all_encoded[l[3]], self.all_encoded[l[4]], self.all_encoded[l[5]], self.all_encoded[l[6]], self.all_encoded[l[7]] #self.embed_vectors1['class'][self.all_encoded[l[3]]], self.embed_vectors1['order'][self.all_encoded[l[4]]], self.embed_vectors1['family'][self.all_encoded[l[5]]], self.embed_vectors1['genus'][self.all_encoded[l[6]]], self.embed_vectors2['species_glc_id'][int(l[7])]\n",
    "            #c, o, f, g, s = self.embeddings[l[3]], self.embeddings[l[4]], self.embeddings[l[5]], self.embeddings[l[6]], self.embeddings[l[7]]\n",
    "            d=np.zeros(56)\n",
    "            d[o]=1\n",
    "            self.y_test.append(d)#,[o],[f],[g],[s]])\n",
    "        \n",
    "    def ordered_call(self, root_dir, csv_file):\n",
    "        print(\"Creating the data preprocessing object and loading csv\")\n",
    "        self.init_load(root_dir, csv_file)\n",
    "        print(\"Creating unique mappings for labels\")\n",
    "        self.create_mappings_for_unique_labels()\n",
    "        print(\"Loading test and train image paths and corresponding labels\")\n",
    "        self.train_test_data_loading()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T17:54:10.146447Z",
     "start_time": "2018-05-26T17:54:10.094785Z"
    }
   },
   "outputs": [],
   "source": [
    "data = Data_Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T17:55:32.803213Z",
     "start_time": "2018-05-26T17:54:10.804615Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the data preprocessing object and loading csv\n",
      "Creating unique mappings for labels\n",
      "Loading test and train image paths and corresponding labels\n"
     ]
    }
   ],
   "source": [
    "data.ordered_call(root_dir=\"Data/Hierarchial Data/\", csv_file=\"occurrences_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T17:55:33.089418Z",
     "start_time": "2018-05-26T17:55:32.805272Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.y_train, data.y_test = np.array(data.y_train).reshape(-1,1), np.array(data.y_test).reshape(-1,1)\n",
    "data.x_train, data.y_train, data.x_test, data.y_test = np.array(data.x_train), np.array(data.y_train), np.array(data.x_test), np.array(data.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T17:55:33.095996Z",
     "start_time": "2018-05-26T17:55:33.091383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T17:55:33.213863Z",
     "start_time": "2018-05-26T17:55:33.097750Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN_Model:\n",
    "    \n",
    "    def __init__(self, data_object):\n",
    "        self.img_height = 64\n",
    "        self.img_width = 64\n",
    "        self.img_channels = 3\n",
    "        self.cardinality = 32\n",
    "        self.data_object = data_object\n",
    "        self.num_classes = len(data_object.all_encoded.keys())\n",
    "    \n",
    "    def model_create(self, time_steps, batch_size):\n",
    "        image_tensor = layers.Input(shape=(self.img_height, self.img_width, self.img_channels))\n",
    "        #network_output = self.residual_network(image_tensor)  \n",
    "        model=MobileNet(include_top=True, weights=None, input_tensor=None, input_shape=(64,64,3), pooling=None, classes=10,alpha=1,dropout=0.2)\n",
    "        #model = models(inputs=[image_tensor], outputs=[network_output])\n",
    "        print(model.summary())\n",
    "        # Compiling the CNN\n",
    "        model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy','mae'])\n",
    "        return model\n",
    "    \n",
    "    def fit_generator(self, num_epochs=10, batch_size=32, crop_size=16, time_steps=5):        \n",
    "        try:\n",
    "            classifier = load_model(\"Code/Models/CNN_LSTM_Embedded_ResNext2.h5\")\n",
    "        except:\n",
    "            print(\"Training\")\n",
    "            classifier = self.model_create(time_steps=time_steps, batch_size=batch_size)\n",
    "            train_data = ImageDataGenerator(self.data_object.x_train, self.data_object.y_train, batch_size, crop_size)\n",
    "            #test_data = ImageDataGenerator(self.data_object.x_test, self.data_object.y_test, batch_size, crop_size)\n",
    "            early_stop=EarlyStopping(monitor='loss',patience=1,verbose=0, mode='auto')\n",
    "            history = classifier.fit_generator(train_data, epochs=num_epochs, use_multiprocessing=True,shuffle=True, callbacks=[early_stop])\n",
    "            return classifier\n",
    "            #Error saving the file.\n",
    "            classifier.save(\"Code/Models/CNN_LSTM_Embedded_ResNext2.h5\")\n",
    "        print(\"Testing\")\n",
    "        test_data = ImageDataGenerator(self.data_object.x_test, self.data_object.y_test, batch_size, crop_size)\n",
    "        scores = classifier.evaluate_generator(test_data, use_multiprocessing=True)\n",
    "        print(\"Loss : \", scores[0])\n",
    "        print(\"Metrics : \", scores[1:])\n",
    "        return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T17:55:33.391968Z",
     "start_time": "2018-05-26T17:55:33.216487Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, x_metadata, y_metadata, batch_size, crop_size):\n",
    "        self.x = x_metadata\n",
    "        self.y = y_metadata\n",
    "        self.batch_size = batch_size\n",
    "        self.cp = crop_size\n",
    "        self.dic = {0:[0,120,165,210],1:[35,62,85],2:[7,22,50],3:[0,1,2,3,4],4:[20,60,140],5:[60,100],6:[0,1,2,3,4],7:[1,2,4,8],8:[1,2],9:[0,1,2,3,4]}\n",
    "        self.conv_dic = {0:[133,1176],1:[-10.00984,18.36730],2:[7.846126,20.94560],3:[41.182110,59.95573],4:[302.772980,777.74048],5:[6.182446,36.54550],6:[-28.248663,5.33183],7:[16.744829,41.94211],8:[-14.122952,22.96798],9:[-17.672335,26.44534],10:[-2.738379,26.44534],11:[-17.672335,11.73241],12:[318.297485,2543.30225],13:[43.063732,285.43790],14:[3.022581,135.58406],15:[8.283675,57.78888],16:[121.616867,855.52594],17:[19.868601,421.27750],18:[19.868601,851.60620],19:[60.590000,520.31244],20:[-187.999999,4672.000000]}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    \n",
    "    def binarization(self,image,un):\n",
    "        img = np.zeros((64,64,len(un)))\n",
    "        for i in range(len(un)):\n",
    "            img[:,:,i] = (image.copy())\n",
    "            img[:,:,i][img[:,:,i] != un[i]] = 0\n",
    "        return img   \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        x = []\n",
    "        for i in range(len(batch_x)):\n",
    "            tempf = tif.imread(batch_x[i])[:3,:,:]\n",
    "            for k in range(3):\n",
    "                tempf[k] = self.conv_dic[k][0] + (self.conv_dic[k][1] - self.conv_dic[k][0]) * ((tempf[k]/255.0) - 0.1) / 0.8\n",
    "            tempf = np.transpose(tempf,(1,2,0))\n",
    "            \n",
    "#             l = []\n",
    "#             temp = tif.imread(batch_x[i])[21:,:,:]\n",
    "#             for k in range(10):\n",
    "#                 un = self.dic[k]\n",
    "#                 un = un[un != 0]\n",
    "#                 img=np.transpose(self.binarization(temp[k],un),(2,0,1)).tolist()\n",
    "#                 l.extend(img)\n",
    "            x.append(tempf)#np.concatenate((tempf,np.transpose(np.array(l),(1,2,0))), axis=2))\n",
    "        return np.array(x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T17:55:33.559996Z",
     "start_time": "2018-05-26T17:55:33.393780Z"
    }
   },
   "outputs": [],
   "source": [
    "model_object = CNN_Model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T18:46:08.376514Z",
     "start_time": "2018-05-26T17:55:33.563497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 66, 66, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 32, 32, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_1 (ZeroPadding2D)   (None, 34, 34, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 32, 32, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 32, 32, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 16, 16, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 16, 16, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_3 (ZeroPadding2D)   (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 16, 16, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 8, 8, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 8, 8, 256)         32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_5 (ZeroPadding2D)   (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 8, 8, 256)         65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 4, 4, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 4, 4, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_7 (ZeroPadding2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 4, 4, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_8 (ZeroPadding2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 4, 4, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_9 (ZeroPadding2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 4, 4, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_10 (ZeroPadding2D)  (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 4, 4, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_11 (ZeroPadding2D)  (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 4, 4, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 2, 2, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_13 (ZeroPadding2D)  (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 2, 2, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 2, 2, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 10)          10250     \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 1, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 3,239,114\n",
      "Trainable params: 3,217,226\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "4781/4781 [==============================] - 3027s 633ms/step - loss: 0.5934 - acc: 0.8151 - mean_absolute_error: 0.0612\n"
     ]
    }
   ],
   "source": [
    "classifier = model_object.fit_generator(num_epochs=1, batch_size=32, crop_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T16:50:04.653863Z",
     "start_time": "2018-05-26T16:50:02.252Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#classifier = model_object.fit_generator(num_epochs=1, batch_size=32, crop_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T19:11:37.403838Z",
     "start_time": "2018-05-26T18:48:21.227406Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = ImageDataGenerator(data.x_test, data.y_test,32,32)\n",
    "scores = classifier.evaluate_generator(test_data, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T19:11:39.537417Z",
     "start_time": "2018-05-26T19:11:39.529148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.58298367573714815, 0.81986791331021502, 0.05636770922417951]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T19:13:11.580941Z",
     "start_time": "2018-05-26T19:13:11.219007Z"
    }
   },
   "outputs": [],
   "source": [
    " classifier.save(\"Code/Models/MobileNet-Order_classification-3_layers_only.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def residual_network(self, x):\n",
    "#         \"\"\"\n",
    "#         ResNeXt by default. For ResNet set `cardinality` = 1 above.\n",
    "\n",
    "#         \"\"\"\n",
    "#         def add_common_layers(y):\n",
    "#             y = layers.BatchNormalization()(y)\n",
    "#             y = layers.LeakyReLU()(y)\n",
    "\n",
    "#             return y\n",
    "\n",
    "#         def grouped_convolution(y, nb_channels, _strides):\n",
    "#             # when `cardinality` == 1 this is just a standard convolution\n",
    "#             if self.cardinality == 1:\n",
    "#                 return layers.Conv2D(nb_channels, kernel_size=(3, 3), strides=_strides, padding='same')(y)\n",
    "\n",
    "#             assert not nb_channels % self.cardinality\n",
    "#             _d = nb_channels // self.cardinality\n",
    "\n",
    "#             # in a grouped convolution layer, input and output channels are divided into `cardinality` groups,\n",
    "#             # and convolutions are separately performed within each group\n",
    "#             groups = []\n",
    "#             for j in range(self.cardinality):\n",
    "#                 group = layers.Lambda(lambda z: z[:, :, :, j * _d:j * _d + _d])(y)\n",
    "#                 groups.append(layers.Conv2D(_d, kernel_size=(3, 3), strides=_strides, padding='same')(group))\n",
    "\n",
    "#             # the grouped convolutional layer concatenates them as the outputs of the layer\n",
    "#             y = layers.concatenate(groups)\n",
    "\n",
    "#             return y\n",
    "\n",
    "#         def residual_block(y, nb_channels_in, nb_channels_out, _strides=(1, 1), _project_shortcut=False):\n",
    "#             \"\"\"\n",
    "#             Our network consists of a stack of residual blocks. These blocks have the same topology,\n",
    "#             and are subject to two simple rules:\n",
    "#             - If producing spatial maps of the same size, the blocks share the same hyper-parameters (width and filter sizes).\n",
    "#             - Each time the spatial map is down-sampled by a factor of 2, the width of the blocks is multiplied by a factor of 2.\n",
    "#             \"\"\"\n",
    "#             shortcut = y\n",
    "\n",
    "#             # we modify the residual building block as a bottleneck design to make the network more economical\n",
    "#             y = layers.Conv2D(nb_channels_in, kernel_size=(1, 1), strides=(1, 1), padding='same')(y)\n",
    "#             y = add_common_layers(y)\n",
    "\n",
    "#             # ResNeXt (identical to ResNet when `cardinality` == 1)\n",
    "#             y = grouped_convolution(y, nb_channels_in, _strides=_strides)\n",
    "#             y = add_common_layers(y)\n",
    "\n",
    "#             y = layers.Conv2D(nb_channels_out, kernel_size=(1, 1), strides=(1, 1), padding='same')(y)\n",
    "#             # batch normalization is employed after aggregating the transformations and before adding to the shortcut\n",
    "#             y = layers.BatchNormalization()(y)\n",
    "\n",
    "#             # identity shortcuts used directly when the input and output are of the same dimensions\n",
    "#             if _project_shortcut or _strides != (1, 1):\n",
    "#                 # when the dimensions increase projection shortcut is used to match dimensions (done by 1×1 convolutions)\n",
    "#                 # when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2\n",
    "#                 shortcut = layers.Conv2D(nb_channels_out, kernel_size=(1, 1), strides=_strides, padding='same')(shortcut)\n",
    "#                 shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "#             y = layers.add([shortcut, y])\n",
    "\n",
    "#             # relu is performed right after each batch normalization,\n",
    "#             # expect for the output of the block where relu is performed after the adding to the shortcut\n",
    "#             y = layers.LeakyReLU()(y)\n",
    "\n",
    "#             return y\n",
    "\n",
    "#         # conv1\n",
    "#         x = layers.Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='same')(x)\n",
    "#         x = add_common_layers(x)\n",
    "\n",
    "#         # conv2\n",
    "#         x = layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "#         for i in range(3):\n",
    "#             project_shortcut = True if i == 0 else False\n",
    "#             x = residual_block(x, 128, 256, _project_shortcut=project_shortcut)\n",
    "\n",
    "#         # conv3\n",
    "#         for i in range(4):\n",
    "#             # down-sampling is performed by conv3_1, conv4_1, and conv5_1 with a stride of 2\n",
    "#             strides = (2, 2) if i == 0 else (1, 1)\n",
    "#             x = residual_block(x, 256, 512, _strides=strides)\n",
    "\n",
    "#         # conv4\n",
    "#         for i in range(6):\n",
    "#             strides = (2, 2) if i == 0 else (1, 1)\n",
    "#             x = residual_block(x, 512, 1024, _strides=strides)\n",
    "\n",
    "#         # conv5\n",
    "#         for i in range(3):\n",
    "#             strides = (2, 2) if i == 0 else (1, 1)\n",
    "#             x = residual_block(x, 1024, 2048, _strides=strides)\n",
    "\n",
    "#         x = layers.GlobalAveragePooling2D()(x)\n",
    "        \n",
    "#         x = layers.RepeatVector(5)(x)\n",
    "#         x = layers.LSTM(256, return_sequences=True)(x)\n",
    "#         x = layers.TimeDistributed(layers.Dense(128, activation='relu'))(x)\n",
    "#         x = layers.TimeDistributed(layers.Dense(self.num_classes, activation='softmax'))(x)\n",
    "\n",
    "#         return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
